"""
Hiperparametre Optimizasyonu Rehberi
Bu modÃ¼l farklÄ± hiperparametre kombinasyonlarÄ±nÄ± test eder ve sonuÃ§larÄ± karÅŸÄ±laÅŸtÄ±rÄ±r
"""

import itertools
import pandas as pd
import numpy as np
from datetime import datetime

class HyperparameterTuner:
    def __init__(self):
        self.results = []
        
    def suggest_parameters_for_beginners(self):
        """Yeni baÅŸlayanlar iÃ§in Ã¶nerilen parametre aralÄ±klarÄ±"""
        suggestions = {
            "hidden_layers": {
                "values": [1, 2, 3, 4],
                "explanation": "Az katman: Basit problemler, Ã‡ok katman: KarmaÅŸÄ±k problemler"
            },
            "neurons": {
                "values": [8, 16, 32, 64, 128],
                "explanation": "Az nÃ¶ron: HÄ±zlÄ± ama basit, Ã‡ok nÃ¶ron: YavaÅŸ ama gÃ¼Ã§lÃ¼"
            },
            "activation": {
                "values": ['relu', 'sigmoid', 'tanh'],
                "explanation": "ReLU: Ã‡oÄŸu durumda en iyi, Sigmoid/Tanh: Ã–zel durumlar iÃ§in"
            },
            "optimizer": {
                "values": ['adam', 'rmsprop', 'sgd'],
                "explanation": "Adam: Genelde en iyi, RMSprop: RNN'ler iÃ§in, SGD: Klasik"
            },
            "learning_rate": {
                "values": [0.001, 0.01, 0.1],
                "explanation": "KÃ¼Ã§Ã¼k: YavaÅŸ Ã¶ÄŸrenme, BÃ¼yÃ¼k: HÄ±zlÄ± ama kararsÄ±z"
            },
            "batch_size": {
                "values": [16, 32, 64, 128],
                "explanation": "KÃ¼Ã§Ã¼k: Daha sÄ±k gÃ¼ncelleme, BÃ¼yÃ¼k: Daha kararlÄ± gradient"
            }
        }
        
        print("ğŸ¯ BAÅLANGIÃ‡ Ä°Ã‡Ä°N HÄ°PERPARAMETRE REHBERÄ°")
        print("="*60)
        
        for param, info in suggestions.items():
            print(f"\nğŸ“Š {param.upper()}:")
            print(f"   Ã–nerilen deÄŸerler: {info['values']}")
            print(f"   ğŸ’¡ AÃ§Ä±klama: {info['explanation']}")
        
        return suggestions
    
    def run_parameter_comparison(self, param_grid, train_function, X_train, y_train, X_test, y_test):
        """FarklÄ± parametre kombinasyonlarÄ±nÄ± test eder"""
        print("\nğŸ”¬ PARAMETRE KARÅILAÅTIRMA TESTÄ° BAÅLIYOR...")
        print("="*60)
        
        # Parametre kombinasyonlarÄ± oluÅŸtur
        keys = param_grid.keys()
        values = param_grid.values()
        combinations = list(itertools.product(*values))
        
        total_tests = len(combinations)
        print(f"Toplam {total_tests} farklÄ± kombinasyon test edilecek...")
        
        for i, combination in enumerate(combinations[:5]):  # Ä°lk 5'ini test et
            params = dict(zip(keys, combination))
            print(f"\nğŸ§ª Test {i+1}/{min(5, total_tests)}: {params}")
            
            try:
                # Model oluÅŸtur ve eÄŸit
                start_time = datetime.now()
                model, history = train_function(params, X_train, y_train, X_test, y_test)
                duration = (datetime.now() - start_time).seconds
                
                # SonuÃ§larÄ± kaydet
                result = {
                    'test_id': i+1,
                    'params': params.copy(),
                    'duration': duration,
                    'final_accuracy': history.history.get('accuracy', [0])[-1] if history else 0,
                    'final_loss': history.history.get('loss', [0])[-1] if history else 0,
                    'best_val_accuracy': max(history.history.get('val_accuracy', [0])) if history else 0
                }
                self.results.append(result)
                
                print(f"   âœ… SonuÃ§: DoÄŸruluk={result['final_accuracy']:.4f}, SÃ¼re={duration}s")
                
            except Exception as e:
                print(f"   âŒ Hata: {str(e)}")
        
        self.display_comparison_results()
    
    def display_comparison_results(self):
        """Test sonuÃ§larÄ±nÄ± karÅŸÄ±laÅŸtÄ±rmalÄ± olarak gÃ¶sterir"""
        if not self.results:
            print("âŒ HenÃ¼z test sonucu bulunmuyor.")
            return
        
        print("\nğŸ“Š TEST SONUÃ‡LARI KARÅILAÅTIRMASI")
        print("="*80)
        
        # En iyi sonuÃ§larÄ± bul
        best_accuracy = max(self.results, key=lambda x: x['final_accuracy'])
        fastest = min(self.results, key=lambda x: x['duration'])
        
        print(f"ğŸ† EN Ä°YÄ° DOÄRULUK: Test {best_accuracy['test_id']}")
        print(f"   Parametreler: {best_accuracy['params']}")
        print(f"   DoÄŸruluk: {best_accuracy['final_accuracy']:.4f}")
        print(f"   SÃ¼re: {best_accuracy['duration']}s")
        
        print(f"\nâš¡ EN HIZLI: Test {fastest['test_id']}")
        print(f"   Parametreler: {fastest['params']}")
        print(f"   DoÄŸruluk: {fastest['final_accuracy']:.4f}")
        print(f"   SÃ¼re: {fastest['duration']}s")
        
        # DetaylÄ± tablo
        print(f"\nğŸ“‹ DETAYLI SONUÃ‡LAR:")
        print("-"*80)
        print(f"{'Test':<6} {'DoÄŸruluk':<10} {'KayÄ±p':<10} {'SÃ¼re':<8} {'Parametreler'}")
        print("-"*80)
        
        for result in sorted(self.results, key=lambda x: x['final_accuracy'], reverse=True):
            params_str = str(result['params'])[:50] + "..." if len(str(result['params'])) > 50 else str(result['params'])
            print(f"{result['test_id']:<6} {result['final_accuracy']:<10.4f} {result['final_loss']:<10.4f} "
                  f"{result['duration']:<8}s {params_str}")
    
    def explain_parameter_effects(self):
        """Her parametrenin model Ã¼zerindeki etkisini aÃ§Ä±klar"""
        explanations = {
            "Learning Rate (Ã–ÄŸrenme OranÄ±)": """
ğŸ¯ Ne iÅŸe yarar: Modelin ne kadar hÄ±zlÄ± Ã¶ÄŸreneceÄŸini belirler
ğŸ“ˆ Ã‡ok yÃ¼ksek (0.1+): Model Ã§ok hÄ±zlÄ± Ã¶ÄŸrenmeye Ã§alÄ±ÅŸÄ±r, optimum noktayÄ± kaÃ§Ä±rabilir
ğŸ“‰ Ã‡ok dÃ¼ÅŸÃ¼k (0.0001-): Model Ã§ok yavaÅŸ Ã¶ÄŸrenir, eÄŸitim Ã§ok uzun sÃ¼rer  
âœ… Ã–nerilen: 0.001 - 0.01 arasÄ± baÅŸlayÄ±n
            """,
            "Batch Size (Toplu Boyut)": """
ğŸ¯ Ne iÅŸe yarar: Her gÃ¼ncellemede kaÃ§ Ã¶rnek kullanÄ±lacaÄŸÄ±nÄ± belirler
ğŸ“ˆ BÃ¼yÃ¼k batch (128+): Daha kararlÄ± gradientler, daha az gÃ¼nceleme
ğŸ“‰ KÃ¼Ã§Ã¼k batch (16-32): Daha sÄ±k gÃ¼nceleme, daha fazla noise
âœ… Ã–nerilen: 32-64 arasÄ± deneyerek baÅŸlayÄ±n
            """,
            "Hidden Layers (Gizli Katmanlar)": """  
ğŸ¯ Ne iÅŸe yarar: Modelin karmaÅŸÄ±klÄ±ÄŸÄ±nÄ± ve Ã¶ÄŸrenme kapasitesini artÄ±rÄ±r
ğŸ“ˆ Ã‡ok katman (5+): KarmaÅŸÄ±k problemler iÃ§in gÃ¼Ã§lÃ¼ ama overfitting riski
ğŸ“‰ Az katman (1-2): Basit problemler iÃ§in yeterli, hÄ±zlÄ± eÄŸitim
âœ… Ã–nerilen: 2-3 katmanla baÅŸlayÄ±n, sonra artÄ±rÄ±n
            """
        }
        
        print("ğŸ“š HÄ°PERPARAMETRE ETKÄ°LERÄ° REHBERÄ°")
        print("="*60)
        
        for param, explanation in explanations.items():
            print(f"\n{param}")
            print(explanation)
            input("Devam etmek iÃ§in ENTER tuÅŸuna basÄ±nÄ±z...")

# Test iÃ§in Ã¶rnek fonksiyon
def create_simple_test_function():
    """Basit bir test fonksiyonu oluÅŸturur"""
    def dummy_train_function(params, X_train, y_train, X_test, y_test):
        """Test amaÃ§lÄ± sahte eÄŸitim fonksiyonu"""
        import time
        import random
        
        # Sahte eÄŸitim sÃ¼resi (parametre karmaÅŸÄ±klÄ±ÄŸÄ±na gÃ¶re)
        complexity = params.get('neurons', 32) * params.get('hidden_layers', 2) 
        time.sleep(min(complexity / 1000, 3))  # Maksimum 3 saniye bekle
        
        # Sahte sonuÃ§lar
        class FakeHistory:
            def __init__(self):
                epochs = 10
                base_acc = random.uniform(0.7, 0.9)
                self.history = {
                    'accuracy': [base_acc + random.uniform(-0.1, 0.1) for _ in range(epochs)],
                    'loss': [random.uniform(0.1, 0.5) for _ in range(epochs)],
                    'val_accuracy': [base_acc + random.uniform(-0.15, 0.05) for _ in range(epochs)]
                }
        
        return None, FakeHistory()
    
    return dummy_train_function

if __name__ == "__main__":
    tuner = HyperparameterTuner()
    
    print("ğŸ”§ HÄ°PERPARAMETRE OPTÄ°MÄ°ZASYONU REHBERÄ°")
    choice = input("""
1. BaÅŸlangÄ±Ã§ parametreleri Ã¶nerilerini gÃ¶r
2. Parametre etkilerini Ã¶ÄŸren  
3. Sahte test Ã§alÄ±ÅŸtÄ±r (demo)
SeÃ§iminiz: """)
    
    if choice == "1":
        tuner.suggest_parameters_for_beginners()
    elif choice == "2":
        tuner.explain_parameter_effects()
    elif choice == "3":
        # Demo test
        param_grid = {
            'neurons': [16, 32],
            'hidden_layers': [2, 3],
            'learning_rate': [0.001, 0.01]
        }
        dummy_data = (None, None, None, None)  # Sahte veri
        test_func = create_simple_test_function()
        tuner.run_parameter_comparison(param_grid, test_func, *dummy_data)