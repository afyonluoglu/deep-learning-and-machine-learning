"""
Model KarÅŸÄ±laÅŸtÄ±rma ve Analiz AracÄ±
FarklÄ± model mimarilerini karÅŸÄ±laÅŸtÄ±rÄ±r ve gÃ¶rselleÅŸtirir
"""

import matplotlib.pyplot as plt
import pandas as pd
import numpy as np
from datetime import datetime
import json

class ModelComparison:
    def __init__(self):
        self.models_tested = []
        self.comparison_results = pd.DataFrame()
        
    def add_model_result(self, model_name, architecture, history, test_accuracy, test_loss, training_time):
        """Model sonuÃ§larÄ±nÄ± kaydet"""
        result = {
            'model_name': model_name,
            'architecture': architecture,
            'final_train_accuracy': history.history['accuracy'][-1] if history and 'accuracy' in history.history else 0,
            'final_val_accuracy': history.history['val_accuracy'][-1] if history and 'val_accuracy' in history.history else 0,
            'test_accuracy': test_accuracy,
            'final_train_loss': history.history['loss'][-1] if history and 'loss' in history.history else 0,
            'final_val_loss': history.history['val_loss'][-1] if history and 'val_loss' in history.history else 0,
            'test_loss': test_loss,
            'training_time': training_time,
            'overfitting_score': self._calculate_overfitting(history),
            'convergence_epoch': self._find_convergence_epoch(history),
            'stability_score': self._calculate_stability(history),
            'timestamp': datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        }
        
        self.models_tested.append(result)
        self.comparison_results = pd.DataFrame(self.models_tested)
        
    def _calculate_overfitting(self, history):
        """Overfitting skorunu hesapla"""
        if not history or 'val_accuracy' not in history.history or 'accuracy' not in history.history:
            return 0
            
        train_acc = np.array(history.history['accuracy'])
        val_acc = np.array(history.history['val_accuracy'])
        
        # Son 5 epoch'un ortalama farkÄ±
        if len(train_acc) >= 5:
            train_avg = np.mean(train_acc[-5:])
            val_avg = np.mean(val_acc[-5:])
            return max(0, train_avg - val_avg)  # Pozitif deÄŸer overfitting gÃ¶sterir
        return 0
    
    def _find_convergence_epoch(self, history):
        """Modelin yakÄ±nsadÄ±ÄŸÄ± epoch'u bul"""
        if not history or 'loss' not in history.history:
            return 0
            
        losses = history.history['loss']
        if len(losses) < 3:
            return len(losses)
            
        # Loss deÄŸiÅŸiminin %1'in altÄ±na dÃ¼ÅŸtÃ¼ÄŸÃ¼ noktayÄ± bul
        for i in range(2, len(losses)):
            recent_change = abs(losses[i] - losses[i-1]) / losses[i-1]
            if recent_change < 0.01:  # %1'den az deÄŸiÅŸim
                return i + 1
        return len(losses)
    
    def _calculate_stability(self, history):
        """EÄŸitim kararlÄ±lÄ±ÄŸÄ±nÄ± hesapla (loss variance)"""
        if not history or 'loss' not in history.history:
            return 0
            
        losses = np.array(history.history['loss'])
        if len(losses) < 2:
            return 0
            
        # Loss deÄŸerlerindeki varyans (dÃ¼ÅŸÃ¼k = daha kararlÄ±)
        return 1 / (1 + np.var(losses))  # 0-1 arasÄ± normalize
    
    def create_comparison_dashboard(self):
        """KarÅŸÄ±laÅŸtÄ±rma dashboard'u oluÅŸtur"""
        if self.comparison_results.empty:
            print("âŒ HenÃ¼z karÅŸÄ±laÅŸtÄ±rÄ±lacak model bulunmuyor.")
            return
            
        fig, axes = plt.subplots(2, 3, figsize=(18, 12))
        fig.suptitle('MODEL KARÅžILAÅžTIRMA DASHBOARD', fontsize=16, fontweight='bold')
        
        # 1. DoÄŸruluk KarÅŸÄ±laÅŸtÄ±rmasÄ±
        axes[0,0].bar(range(len(self.comparison_results)), self.comparison_results['test_accuracy'])
        axes[0,0].set_title('Test DoÄŸruluÄŸu')
        axes[0,0].set_xticks(range(len(self.comparison_results)))
        axes[0,0].set_xticklabels(self.comparison_results['model_name'], rotation=45)
        
        # 2. Overfitting Analizi  
        axes[0,1].bar(range(len(self.comparison_results)), self.comparison_results['overfitting_score'])
        axes[0,1].set_title('Overfitting Skoru (DÃ¼ÅŸÃ¼k = Ä°yi)')
        axes[0,1].set_xticks(range(len(self.comparison_results)))
        axes[0,1].set_xticklabels(self.comparison_results['model_name'], rotation=45)
        
        # 3. EÄŸitim SÃ¼resi
        axes[0,2].bar(range(len(self.comparison_results)), self.comparison_results['training_time'])
        axes[0,2].set_title('EÄŸitim SÃ¼resi (saniye)')
        axes[0,2].set_xticks(range(len(self.comparison_results)))
        axes[0,2].set_xticklabels(self.comparison_results['model_name'], rotation=45)
        
        # 4. YakÄ±nsama HÄ±zÄ±
        axes[1,0].bar(range(len(self.comparison_results)), self.comparison_results['convergence_epoch'])
        axes[1,0].set_title('YakÄ±nsama Epoch\'u (DÃ¼ÅŸÃ¼k = HÄ±zlÄ±)')
        axes[1,0].set_xticks(range(len(self.comparison_results)))
        axes[1,0].set_xticklabels(self.comparison_results['model_name'], rotation=45)
        
        # 5. KararlÄ±lÄ±k Skoru
        axes[1,1].bar(range(len(self.comparison_results)), self.comparison_results['stability_score'])
        axes[1,1].set_title('KararlÄ±lÄ±k Skoru (YÃ¼ksek = Ä°yi)')
        axes[1,1].set_xticks(range(len(self.comparison_results)))
        axes[1,1].set_xticklabels(self.comparison_results['model_name'], rotation=45)
        
        # 6. Genel Performans Radar
        categories = ['Test Accuracy', 'Anti-Overfitting', 'Speed', 'Stability']
        
        # Normalize scores for radar chart (0-1)
        normalized_scores = []
        for idx, row in self.comparison_results.iterrows():
            scores = [
                row['test_accuracy'],
                1 - min(1, row['overfitting_score']),  # Ters Ã§evir, dÃ¼ÅŸÃ¼k overfitting iyi
                1 / (1 + row['training_time']/60),     # HÄ±z skoru, normalize
                row['stability_score']
            ]
            normalized_scores.append(scores)
        
        # Radar chart iÃ§in polar subplot
        axes[1,2].remove()
        ax_radar = fig.add_subplot(2, 3, 6, projection='polar')
        
        angles = np.linspace(0, 2 * np.pi, len(categories), endpoint=False)
        angles = np.concatenate((angles, [angles[0]]))  # DÃ¶ngÃ¼yÃ¼ kapat
        
        for i, scores in enumerate(normalized_scores):
            values = scores + [scores[0]]  # DÃ¶ngÃ¼yÃ¼ kapat
            ax_radar.plot(angles, values, 'o-', linewidth=2, 
                         label=self.comparison_results.iloc[i]['model_name'])
            ax_radar.fill(angles, values, alpha=0.25)
            
        ax_radar.set_xticks(angles[:-1])
        ax_radar.set_xticklabels(categories)
        ax_radar.set_ylim(0, 1)
        ax_radar.set_title('Genel Performans Analizi')
        ax_radar.legend(loc='upper right', bbox_to_anchor=(1.3, 1.0))
        
        plt.tight_layout()
        plt.show()
    
    def generate_recommendation_report(self):
        """Model seÃ§imi iÃ§in Ã¶neri raporu oluÅŸtur"""
        if self.comparison_results.empty:
            print("âŒ HenÃ¼z analiz edilecek model bulunmuyor.")
            return
            
        print("ðŸ“Š MODEL DEÄžERLENDÄ°RME RAPORU")
        print("="*60)
        
        # En iyi modeller
        best_accuracy = self.comparison_results.loc[self.comparison_results['test_accuracy'].idxmax()]
        fastest = self.comparison_results.loc[self.comparison_results['training_time'].idxmin()]
        most_stable = self.comparison_results.loc[self.comparison_results['stability_score'].idxmax()]
        least_overfitting = self.comparison_results.loc[self.comparison_results['overfitting_score'].idxmin()]
        
        print(f"\nðŸ† EN Ä°YÄ° DOÄžRULUK: {best_accuracy['model_name']}")
        print(f"   Test DoÄŸruluÄŸu: {best_accuracy['test_accuracy']:.4f}")
        print(f"   Mimari: {best_accuracy['architecture']}")
        
        print(f"\nâš¡ EN HIZLI EÄžÄ°TÄ°M: {fastest['model_name']}")
        print(f"   EÄŸitim SÃ¼resi: {fastest['training_time']:.1f} saniye")
        print(f"   Test DoÄŸruluÄŸu: {fastest['test_accuracy']:.4f}")
        
        print(f"\nðŸŽ¯ EN KARALI: {most_stable['model_name']}")
        print(f"   KararlÄ±lÄ±k Skoru: {most_stable['stability_score']:.4f}")
        print(f"   Test DoÄŸruluÄŸu: {most_stable['test_accuracy']:.4f}")
        
        print(f"\nðŸ›¡ï¸  EN AZ OVERFITTING: {least_overfitting['model_name']}")
        print(f"   Overfitting Skoru: {least_overfitting['overfitting_score']:.4f}")
        print(f"   Test DoÄŸruluÄŸu: {least_overfitting['test_accuracy']:.4f}")
        
        # Genel Ã¶neri
        print(f"\nðŸ’¡ Ã–NERÄ°:")
        
        # Composite score hesapla
        self.comparison_results['composite_score'] = (
            self.comparison_results['test_accuracy'] * 0.4 +
            (1 - self.comparison_results['overfitting_score'].clip(0, 1)) * 0.3 +
            self.comparison_results['stability_score'] * 0.2 +
            (1 / (1 + self.comparison_results['training_time']/60)) * 0.1
        )
        
        best_overall = self.comparison_results.loc[self.comparison_results['composite_score'].idxmax()]
        print(f"   Genel performans iÃ§in en iyi: {best_overall['model_name']}")
        print(f"   Composite Score: {best_overall['composite_score']:.4f}")
        
        # DetaylÄ± karÅŸÄ±laÅŸtÄ±rma tablosu
        print(f"\nðŸ“‹ DETAYLI KARÅžILAÅžTIRMA:")
        print("-"*100)
        print(f"{'Model':<20} {'Test Acc':<10} {'Overfitting':<12} {'SÃ¼re(s)':<10} {'KararlÄ±lÄ±k':<12} {'Composite':<12}")
        print("-"*100)
        
        for _, row in self.comparison_results.sort_values('composite_score', ascending=False).iterrows():
            print(f"{row['model_name']:<20} {row['test_accuracy']:<10.4f} {row['overfitting_score']:<12.4f} "
                  f"{row['training_time']:<10.1f} {row['stability_score']:<12.4f} {row['composite_score']:<12.4f}")
    
    def save_results(self, filename="model_comparison_results.json"):
        """SonuÃ§larÄ± dosyaya kaydet"""
        if self.models_tested:
            with open(filename, 'w', encoding='utf-8') as f:
                json.dump(self.models_tested, f, indent=2, ensure_ascii=False)
            print(f"âœ… SonuÃ§lar {filename} dosyasÄ±na kaydedildi.")
    
    def load_results(self, filename="model_comparison_results.json"):
        """SonuÃ§larÄ± dosyadan yÃ¼kle"""
        try:
            with open(filename, 'r', encoding='utf-8') as f:
                self.models_tested = json.load(f)
                self.comparison_results = pd.DataFrame(self.models_tested)
            print(f"âœ… SonuÃ§lar {filename} dosyasÄ±ndan yÃ¼klendi.")
        except FileNotFoundError:
            print(f"âŒ {filename} dosyasÄ± bulunamadÄ±.")

# Demo iÃ§in test fonksiyonu
def demo_comparison():
    """Demo karÅŸÄ±laÅŸtÄ±rma"""
    import random
    
    comparator = ModelComparison()
    
    # Sahte model sonuÃ§larÄ±
    models = [
        ("Basit Model (2 Katman)", "2x32", 0.82, 0.85, 15),
        ("Derin Model (4 Katman)", "4x64", 0.89, 0.92, 45), 
        ("GeniÅŸ Model (2 Katman)", "2x128", 0.85, 0.88, 25),
        ("KarmaÅŸÄ±k Model (6 Katman)", "6x32", 0.91, 0.78, 75)  # Overfitting Ã¶rneÄŸi
    ]
    
    class FakeHistory:
        def __init__(self, final_acc, final_val_acc):
            epochs = 20
            # Sahte eÄŸitim geÃ§miÅŸi oluÅŸtur
            self.history = {
                'accuracy': [0.5 + (final_acc-0.5) * (i/epochs) + random.uniform(-0.05, 0.05) 
                            for i in range(epochs)],
                'val_accuracy': [0.5 + (final_val_acc-0.5) * (i/epochs) + random.uniform(-0.08, 0.08) 
                                for i in range(epochs)],
                'loss': [1.0 * (1 - i/epochs) + random.uniform(-0.1, 0.1) 
                        for i in range(epochs)],
                'val_loss': [1.0 * (1 - i/epochs) + random.uniform(-0.15, 0.15) 
                            for i in range(epochs)]
            }
    
    for name, arch, test_acc, val_acc, time_taken in models:
        fake_history = FakeHistory(test_acc, val_acc)
        comparator.add_model_result(name, arch, fake_history, test_acc, 
                                   random.uniform(0.2, 0.5), time_taken)
    
    print("ðŸŽ® DEMO: Model KarÅŸÄ±laÅŸtÄ±rma AracÄ±")
    comparator.generate_recommendation_report()
    
    choice = input("\nGÃ¶rsel dashboard'u gÃ¶rmek istiyor musunuz? (y/n): ")
    if choice.lower() == 'y':
        comparator.create_comparison_dashboard()
    
    choice2 = input("SonuÃ§larÄ± kaydetmek istiyor musunuz? (y/n): ")
    if choice2.lower() == 'y':
        comparator.save_results()

if __name__ == "__main__":
    demo_comparison()