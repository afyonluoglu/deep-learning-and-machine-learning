import pandas as pd
import numpy as np
from sklearn.preprocessing import StandardScaler, MinMaxScaler, LabelEncoder, OneHotEncoder
from sklearn.model_selection import train_test_split
import os

# Veriyi yÃ¼kle
data = pd.read_csv(r'c:\Users\ASUS\Desktop\Python with AI\Yapay Zeka - AI Traning Kits\02 Deep Learning\demo_dataset.csv')

# Veri setinin temel bilgilerini gÃ¶ster
print('ğŸ“Š Veri Seti Bilgileri:')
print(f'SatÄ±r sayÄ±sÄ±: {len(data)}')
print(f'SÃ¼tun sayÄ±sÄ±: {len(data.columns)}')
print(f'SÃ¼tunlar: {list(data.columns)}')
print('\nÄ°lk 5 satÄ±r:')
print(data.head())

# Eksik deÄŸerleri kontrol et
missing_data = data.isnull().sum()
if missing_data.any():
    print('\nâš ï¸ Eksik DeÄŸerler:')
    for col, missing_count in missing_data[missing_data > 0].items():
        print(f'  {col}: {missing_count}')

    # Eksik deÄŸerleri doldur
    data.loc[data['salary'].isnull(), 'salary'] = data['salary'].median()

else:
    print('âœ… Eksik deÄŸer yok')

# Kategorik sÃ¼tunlarÄ± encode et
categorical_encoders = {}

# gender sÃ¼tunu iÃ§in Label Encoding (2 kategori)
categorical_encoders['gender'] = LabelEncoder()
data['gender'] = categorical_encoders['gender'].fit_transform(data['gender'])

# education sÃ¼tunu iÃ§in One-Hot Encoding (4 kategori)
data = pd.get_dummies(data, columns=['education'], prefix='education')

# SayÄ±sal sÃ¼tunlarÄ± normalize et (hedef sÃ¼tun hariÃ§)
scaler = StandardScaler()
numeric_features = ['age', 'salary', 'experience', 'score']
print(f'\nğŸ“ Normalize edilecek sayÄ±sal sÃ¼tunlar: {numeric_features}')

# Normalizasyon Ã¶ncesi istatistikler
print('\nğŸ“Š Normalizasyon Ã–ncesi Ä°statistikler:')
print(data[numeric_features].describe())

# Normalizasyonu uygula
data[numeric_features] = scaler.fit_transform(data[numeric_features])

# Normalizasyon sonrasÄ± istatistikler
print('\nğŸ“Š Normalizasyon SonrasÄ± Ä°statistikler:')
print(data[numeric_features].describe())

# Hedef sÃ¼tunu (high_earner) sayÄ±sal - ek iÅŸlem gerekmiyor
print(f'\nğŸ¯ Hedef sÃ¼tunu: high_earner (sayÄ±sal)')

# Son veri seti durumu
print(f'\nğŸ“‹ Ä°ÅŸlenmiÅŸ Veri Seti:')
print(f'Boyut: {data.shape}')
print(f'SÃ¼tunlar: {list(data.columns)}')

# Ã–zellik ve hedef deÄŸiÅŸkenleri ayÄ±r
if 'high_earner' in data.columns:
    X = data.drop('high_earner', axis=1)
    y = data['high_earner']
else:
    print('âŒ Hedef sÃ¼tunu bulunamadÄ±!')
    print('Mevcut sÃ¼tunlar:', list(data.columns))
    # En son sÃ¼tunu hedef olarak kabul et
    X = data.iloc[:, :-1]
    y = data.iloc[:, -1]
    print(f'Son sÃ¼tun hedef olarak seÃ§ildi: {y.name}')

# EÄŸitim ve test setlerine ayÄ±r
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# SonuÃ§larÄ± gÃ¶ster
print('\nâœ… Veri Ã¶n iÅŸleme tamamlandÄ±!')
print(f'ğŸ“Š EÄŸitim seti boyutu: {X_train.shape}')
print(f'ğŸ“Š Test seti boyutu: {X_test.shape}')
print(f'ğŸ¯ Hedef deÄŸiÅŸken daÄŸÄ±lÄ±mÄ±:')
if hasattr(y, 'value_counts'):
    print(y.value_counts())
else:
    print(f'Min: {y.min()}, Max: {y.max()}, Ortalama: {y.mean():.2f}')

# Opsiyonel: SonuÃ§larÄ± kaydet
save_choice = input('\nÄ°ÅŸlenmiÅŸ veriyi kaydetmek istiyor musunuz? (y/n): ')
if save_choice.lower() == 'y':
    processed_filename = 'processed_data.csv'
    data.to_csv(processed_filename, index=False)
    print(f'âœ… Ä°ÅŸlenmiÅŸ veri {processed_filename} dosyasÄ±na kaydedildi.')