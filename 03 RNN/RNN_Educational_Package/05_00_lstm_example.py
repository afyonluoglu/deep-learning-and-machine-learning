"""
ğŸ”¤ LSTM Ã–RNEÄÄ° - UZUN KISA SÃœRELÄ° HAFIZA
======================================

Bu dosya LSTM (Long Short-Term Memory) aÄŸlarÄ±nÄ± detaylÄ± ÅŸekilde aÃ§Ä±klar.
LSTM'lerin Vanilla RNN'lere gÃ¶re avantajlarÄ±nÄ± praktik Ã¶rneklerle gÃ¶sterir.

LSTM'nin Temel Ã–zellikleri:
1. Cell State (HÃ¼cre Durumu) - Uzun vadeli hafÄ±za
2. Forget Gate - Hangi bilgilerin unutulacaÄŸÄ±nÄ± karar verir
3. Input Gate - Hangi yeni bilgilerin saklanacaÄŸÄ±nÄ± karar verir
4. Output Gate - Hangi bilgilerin Ã§Ä±ktÄ± olacaÄŸÄ±nÄ± karar verir

KullanÄ±m AlanlarÄ±:
- Uzun metinlerin analizi
- Makine Ã§evirisi
- KonuÅŸma tanÄ±ma
- Zaman serisi tahmini (uzun dÃ¶nemli baÄŸÄ±mlÄ±lÄ±klar)
"""

import os
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'
import numpy as np
import matplotlib.pyplot as plt
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense, Dropout
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.layers import Input
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import mean_squared_error, mean_absolute_error
import seaborn as sns

def print_section(title, char="=", single_line:bool=False, width=55):
    title = title
    if not single_line:
        print(f"{char*width}")
    if char == "=":
        title = "ğŸ“‹ "+ title
    print(title)
    print(f"{char*width}")

print_section("ğŸ”¤ LSTM Ã–RNEÄÄ° - UZUN KISA SÃœRELÄ° HAFIZA", char="#", width=80)

print_section("LSTM TEORÄ°SÄ° VE VANILLA RNN KARÅILAÅTIRMASI")

print_section("ğŸ§  LSTM vs Vanilla RNN:", char="-", single_line=True, width=35)

print("Vanilla RNN Problemleri:")
print("  âŒ Vanishing Gradient Problem")
print("  âŒ Uzun vadeli baÄŸÄ±mlÄ±lÄ±klarÄ± Ã¶ÄŸrenemez")
print("  âŒ Gradyanlar kaybolur/patlar")
print("")
print("LSTM Ã‡Ã¶zÃ¼mleri:")
print("  âœ… Cell State ile uzun vadeli hafÄ±za")
print("  âœ… Gate mekanizmalarÄ± ile kontrollÃ¼ bilgi akÄ±ÅŸÄ±")
print("  âœ… Gradyan akÄ±ÅŸÄ±nÄ± korur")
print("  âœ… Selektif unutma ve hatÄ±rlama")

print_section("LSTM GATE MEKANÄ°ZMALARI")

def visualize_lstm_gates():
    """LSTM gate mekanizmalarÄ±nÄ± gÃ¶rselleÅŸtirir"""
    
    fig, axes = plt.subplots(2, 2, figsize=(15, 10))
    fig.suptitle('LSTM Gate MekanizmalarÄ±', fontsize=16, fontweight='bold')
    
    # Forget Gate
    x = np.linspace(0, 10, 100)
    forget_gate = 1 / (1 + np.exp(-(x - 5)))  # Sigmoid
    
    axes[0, 0].plot(x, forget_gate, 'r-', linewidth=3, label='Forget Gate')
    axes[0, 0].set_title('Forget Gate (Unutma KapÄ±sÄ±)', fontweight='bold')
    axes[0, 0].set_xlabel('GiriÅŸ')
    axes[0, 0].set_ylabel('Ã‡Ä±ktÄ± (0-1)')
    axes[0, 0].grid(True, alpha=0.3)
    axes[0, 0].axhline(y=0.5, color='gray', linestyle='--', alpha=0.7)
    axes[0, 0].text(5, 0.3, 'Unutma EÅŸiÄŸi', ha='center', fontsize=10)
    axes[0, 0].legend()
    
    # Input Gate
    input_gate = 1 / (1 + np.exp(-(x - 3)))
    candidate = np.tanh(x - 5)
    
    axes[0, 1].plot(x, input_gate, 'b-', linewidth=3, label='Input Gate')
    axes[0, 1].plot(x, candidate, 'g--', linewidth=2, label='Candidate Values')
    axes[0, 1].set_title('Input Gate (GiriÅŸ KapÄ±sÄ±)', fontweight='bold')
    axes[0, 1].set_xlabel('GiriÅŸ')
    axes[0, 1].set_ylabel('DeÄŸer')
    axes[0, 1].grid(True, alpha=0.3)
    axes[0, 1].legend()
    
    # Cell State
    time = np.arange(20)
    cell_state = np.cumsum(np.random.randn(20) * 0.1) + np.sin(time * 0.5)
    
    axes[1, 0].plot(time, cell_state, 'purple', linewidth=3, marker='o', markersize=6)
    axes[1, 0].set_title('Cell State (HÃ¼cre Durumu)', fontweight='bold')
    axes[1, 0].set_xlabel('Zaman')
    axes[1, 0].set_ylabel('Cell State DeÄŸeri')
    axes[1, 0].grid(True, alpha=0.3)
    axes[1, 0].fill_between(time, cell_state, alpha=0.3, color='purple')
    
    # Output Gate
    output_gate = 1 / (1 + np.exp(-(x - 4)))
    tanh_cell = np.tanh(x - 5)
    
    axes[1, 1].plot(x, output_gate, 'orange', linewidth=3, label='Output Gate')
    axes[1, 1].plot(x, tanh_cell, 'brown', linestyle='--', linewidth=2, label='tanh(Cell State)')
    axes[1, 1].set_title('Output Gate (Ã‡Ä±ktÄ± KapÄ±sÄ±)', fontweight='bold')
    axes[1, 1].set_xlabel('GiriÅŸ')
    axes[1, 1].set_ylabel('DeÄŸer')
    axes[1, 1].grid(True, alpha=0.3)
    axes[1, 1].legend()
    
    plt.tight_layout()
    plt.show()
    
    print("ğŸšª Gate AÃ§Ä±klamalarÄ±:")
    print("-" * 20)
    print("1. ğŸ—‘ï¸ Forget Gate: Hangi bilgilerin Cell State'den silineceÄŸini karar verir")
    print("2. ğŸ“¥ Input Gate: Hangi yeni bilgilerin Cell State'e ekleneceÄŸini karar verir")
    print("3. ğŸ§  Cell State: Uzun vadeli hafÄ±zayÄ± saklar")
    print("4. ğŸ“¤ Output Gate: Cell State'in hangi kÄ±smÄ±nÄ±n Ã§Ä±ktÄ± olacaÄŸÄ±nÄ± karar verir")

visualize_lstm_gates()

print_section("PRATIK Ã–RNEK: HÄ°SSE SENEDÄ° FÄ°YAT TAHMÄ°NÄ°")

def create_complex_stock_data():
    """KarmaÅŸÄ±k hisse senedi verisi oluÅŸturur"""
    
    np.random.seed(42)
    days = 1000
    
    # Trend bileÅŸeni
    trend = np.linspace(100, 200, days)
    
    # Mevsimsel bileÅŸen (aylÄ±k dÃ¶ngÃ¼)
    seasonal = 20 * np.sin(np.arange(days) * 2 * np.pi / 30)
    
    # Uzun vadeli dÃ¶ngÃ¼ (yÄ±llÄ±k)
    long_cycle = 15 * np.sin(np.arange(days) * 2 * np.pi / 365)
    
    # Volatilite (GARCH benzeri)
    volatility = np.zeros(days)
    volatility[0] = 1
    for i in range(1, days):
        volatility[i] = 0.1 + 0.8 * volatility[i-1] + 0.1 * np.random.randn()**2
    
    # Rastgele ÅŸoklar
    shocks = np.random.randn(days) * np.sqrt(volatility)
    
    # Final fiyat
    price = trend + seasonal + long_cycle + shocks * 10
    
    # Pozitif deÄŸerler iÃ§in clamp
    price = np.maximum(price, 50)
    
    return price

# Veri oluÅŸtur
print("ğŸ“Š KarmaÅŸÄ±k hisse senedi verisi oluÅŸturuluyor...")
stock_price = create_complex_stock_data()

# Veriyi gÃ¶rselleÅŸtir
plt.figure(figsize=(15, 8))
plt.subplot(2, 1, 1)
plt.plot(stock_price[:500], 'b-', linewidth=1.5, alpha=0.8)
plt.title('Sentetik Hisse Senedi FiyatÄ± (Ä°lk 500 GÃ¼n)', fontsize=14, fontweight='bold')
plt.xlabel('GÃ¼n')
plt.ylabel('Fiyat ($)')
plt.grid(True, alpha=0.3)

plt.subplot(2, 1, 2)
plt.plot(stock_price[500:], 'r-', linewidth=1.5, alpha=0.8)
plt.title('Son 500 GÃ¼n', fontsize=14, fontweight='bold')
plt.xlabel('GÃ¼n')
plt.ylabel('Fiyat ($)')
plt.grid(True, alpha=0.3)

plt.tight_layout()
plt.show()

print(f"ğŸ“Š Veri istatistikleri:")
print(f"   Toplam gÃ¼n sayÄ±sÄ±: {len(stock_price)}")
print(f"   Ortalama fiyat: ${np.mean(stock_price):.2f}")
print(f"   Min fiyat: ${np.min(stock_price):.2f}")
print(f"   Max fiyat: ${np.max(stock_price):.2f}")
print(f"   Standart sapma: ${np.std(stock_price):.2f}")

print_section("VERÄ° Ã–N Ä°ÅLEME VE HAZIRLAMA")

# Veriyi normalize et
scaler = MinMaxScaler(feature_range=(0, 1))
scaled_data = scaler.fit_transform(stock_price.reshape(-1, 1))

def create_lstm_sequences(data, lookback_days, prediction_days=1):
    """LSTM iÃ§in sequence'ler oluÅŸturur"""
    
    X, y = [], []
    for i in range(lookback_days, len(data) - prediction_days + 1):
        X.append(data[i-lookback_days:i, 0])
        y.append(data[i:i+prediction_days, 0])
    
    return np.array(X), np.array(y)

# Parametre ayarlarÄ±
LOOKBACK_DAYS = 60  # Son 60 gÃ¼nÃ¼ kullan
PREDICTION_DAYS = 5  # 5 gÃ¼n ileriye tahmin

print(f"âš™ï¸ Parametre ayarlarÄ±:")
print(f"   Geriye bakÄ±ÅŸ gÃ¼nleri: {LOOKBACK_DAYS}")
print(f"   Tahmin gÃ¼nleri: {PREDICTION_DAYS}")

# Sequence'ler oluÅŸtur
X, y = create_lstm_sequences(scaled_data, LOOKBACK_DAYS, PREDICTION_DAYS)

# Reshape for LSTM [samples, time steps, features]
X = X.reshape((X.shape[0], X.shape[1], 1))

print(f"ğŸ“ Veri ÅŸekilleri:")
print(f"   X: {X.shape} (Ã¶rnekler, zaman_adÄ±mlarÄ±, Ã¶zellikler)")
print(f"   y: {y.shape} (Ã¶rnekler, tahmin_gÃ¼nleri)")

# Train/validation/test split
train_size = int(len(X) * 0.7)
val_size = int(len(X) * 0.15)

X_train = X[:train_size]
y_train = y[:train_size]
X_val = X[train_size:train_size + val_size]
y_val = y[train_size:train_size + val_size]
X_test = X[train_size + val_size:]
y_test = y[train_size + val_size:]

print(f"ğŸ“Š Veri bÃ¶lÃ¼mlemesi:")
print(f"   EÄŸitim: {len(X_train)} Ã¶rnek ({len(X_train)/len(X)*100:.1f}%)")
print(f"   Validasyon: {len(X_val)} Ã¶rnek ({len(X_val)/len(X)*100:.1f}%)")
print(f"   Test: {len(X_test)} Ã¶rnek ({len(X_test)/len(X)*100:.1f}%)")

print_section("LSTM MODELÄ° TASARIMI")

print("ğŸ—ï¸ GeliÅŸmiÅŸ LSTM modeli oluÅŸturuluyor...")

# Model mimarisi
model = Sequential([
    # Ä°lk LSTM katmanÄ±
    Input(shape=(LOOKBACK_DAYS, 1)),
    LSTM(units=100, return_sequences=True),
    Dropout(0.23),
    
    # Ä°kinci LSTM katmanÄ±
    LSTM(units=100, return_sequences=True),
    Dropout(0.23),
    
    # ÃœÃ§Ã¼ncÃ¼ LSTM katmanÄ±
    LSTM(units=50, return_sequences=False),
    Dropout(0.23),
    
    # Dense katmanlarÄ±
    Dense(50, activation='relu'),
    Dropout(0.15),
    Dense(25, activation='relu'),
    Dense(PREDICTION_DAYS)  # Multi-step prediction
])

print(f"Model: LSTM (units=100) x2, Dropout: 0.23-> LSTM (units=50), Dropout: 0.23 -> Dense (50), Dropout: 0.15 -> Dense (25) -> Dense ({PREDICTION_DAYS})")

# Model derle
optimizer = Adam(learning_rate=0.001)
model.compile(optimizer=optimizer, loss='mse', metrics=['mae'])

print("âœ… Model hazÄ±rlandÄ±!")
print("\nğŸ“‹ MODEL Ã–ZETÄ°:")
model.summary()

print_section("MODEL EÄÄ°TÄ°MÄ°")

print("ğŸš€ LSTM modeli eÄŸitiliyor...")

# Callbacks
early_stopping = tf.keras.callbacks.EarlyStopping(
    monitor='val_loss',
    patience=10,
    restore_best_weights=True
)

reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(
    monitor='val_loss',
    factor=0.5,
    patience=10,
    min_lr=0.0001,
    verbose=1
)

CURRENT_DIR = os.path.dirname(os.path.abspath(__file__))
keras_file = os.path.join(CURRENT_DIR, 'best_lstm_model.keras')
print(f"ğŸ”– En iyi model '{keras_file}' dosyasÄ±na kaydedilecek.")
model_checkpoint = tf.keras.callbacks.ModelCheckpoint(
    keras_file,
    monitor='val_loss',
    save_best_only=True,
    verbose=0
)

# EÄŸitim
history = model.fit(
    X_train, y_train,
    validation_data=(X_val, y_val),
    epochs=100,
    batch_size=32,
    callbacks=[early_stopping, reduce_lr, model_checkpoint],
    verbose=1
)

print("âœ… EÄŸitim tamamlandÄ±!")

print_section("MODEL DEÄERLENDÄ°RME")

# Tahminleri yap
print("ğŸ”® Tahminler hesaplanÄ±yor...")
train_pred = model.predict(X_train, verbose=0)
val_pred = model.predict(X_val, verbose=0)
test_pred = model.predict(X_test, verbose=0)

# Inverse transform (normalizasyonu geri al)
def inverse_transform_predictions(predictions, scaler):
    """Tahminleri orijinal scale'e dÃ¶nÃ¼ÅŸtÃ¼rÃ¼r"""
    predictions_reshaped = predictions.reshape(-1, 1)
    return scaler.inverse_transform(predictions_reshaped).reshape(predictions.shape)

# Sadece ilk gÃ¼nÃ¼n tahminini deÄŸerlendir
train_pred_inv = inverse_transform_predictions(train_pred[:, 0:1], scaler)
val_pred_inv = inverse_transform_predictions(val_pred[:, 0:1], scaler)
test_pred_inv = inverse_transform_predictions(test_pred[:, 0:1], scaler)

y_train_inv = inverse_transform_predictions(y_train[:, 0:1], scaler)
y_val_inv = inverse_transform_predictions(y_val[:, 0:1], scaler)
y_test_inv = inverse_transform_predictions(y_test[:, 0:1], scaler)

# Metrikleri hesapla
def calculate_detailed_metrics(y_true, y_pred, set_name):
    """DetaylÄ± metrikleri hesaplar"""
    mse = mean_squared_error(y_true, y_pred)
    mae = mean_absolute_error(y_true, y_pred)
    rmse = np.sqrt(mse)
    
    # Percentage errors
    mape = np.mean(np.abs((y_true - y_pred) / y_true)) * 100
    
    print(f"\nğŸ“Š {set_name} Metrikleri:")
    print(f"   MSE :  {mse:.6f}")
    print(f"   MAE :  {mae:.4f}")
    print(f"   RMSE: {rmse:.4f}")
    print(f"   MAPE: {mape:.2f}%")
    
    return {'mse': mse, 'mae': mae, 'rmse': rmse, 'mape': mape}

train_metrics = calculate_detailed_metrics(y_train_inv.flatten(), train_pred_inv.flatten(), "EÄŸitim")
val_metrics = calculate_detailed_metrics(y_val_inv.flatten(), val_pred_inv.flatten(), "Validasyon")
test_metrics = calculate_detailed_metrics(y_test_inv.flatten(), test_pred_inv.flatten(), "Test")

print_section("SONUÃ‡LARI GÃ–RSELLEÅTÄ°RME")

# KapsamlÄ± gÃ¶rselleÅŸtirmeler
fig, axes = plt.subplots(3, 2, figsize=(18, 15))

# EÄŸitim geÃ§miÅŸi
axes[0, 0].plot(history.history['loss'], 'b-', label='EÄŸitim Loss', linewidth=2)
axes[0, 0].plot(history.history['val_loss'], 'r-', label='Validasyon Loss', linewidth=2)
axes[0, 0].set_title('Model Loss GeÃ§miÅŸi', fontweight='bold')
axes[0, 0].set_xlabel('Epoch')
axes[0, 0].set_ylabel('Loss')
axes[0, 0].legend()
axes[0, 0].grid(True, alpha=0.3)
axes[0, 0].set_yscale('log')

# MAE geÃ§miÅŸi
axes[0, 1].plot(history.history['mae'], 'b-', label='EÄŸitim MAE', linewidth=2)
axes[0, 1].plot(history.history['val_mae'], 'r-', label='Validasyon MAE', linewidth=2)
axes[0, 1].set_title('Mean Absolute Error', fontweight='bold')
axes[0, 1].set_xlabel('Epoch')
axes[0, 1].set_ylabel('MAE')
axes[0, 1].legend()
axes[0, 1].grid(True, alpha=0.3)

# Test seti tahminleri (scatter plot)
axes[1, 0].scatter(y_test_inv.flatten(), test_pred_inv.flatten(), alpha=0.6, s=30, color='black')
min_val = min(y_test_inv.min(), test_pred_inv.min())
max_val = max(y_test_inv.max(), test_pred_inv.max())
axes[1, 0].plot([min_val, max_val], [min_val, max_val], 'r--', lw=2)
axes[1, 0].set_title('GerÃ§ek vs Tahmin (Test)', fontweight='bold')
axes[1, 0].set_xlabel('GerÃ§ek DeÄŸerler ($)')
axes[1, 0].set_ylabel('Tahmin Edilen DeÄŸerler ($)')
axes[1, 0].grid(True, alpha=0.3)

# Zaman serisi tahminleri (son 200 test Ã¶rneÄŸi)
last_n = min(200, len(y_test_inv))
test_time = range(last_n)
axes[1, 1].plot(test_time, y_test_inv[-last_n:].flatten(), 'b-', 
               label='GerÃ§ek', linewidth=2, alpha=0.8)
axes[1, 1].plot(test_time, test_pred_inv[-last_n:].flatten(), 'r-', 
               label='LSTM Tahmini', linewidth=2, alpha=0.8)
axes[1, 1].set_title('Son 200 Test GÃ¼nÃ¼ - Zaman Serisi', fontweight='bold')
axes[1, 1].set_xlabel('Test GÃ¼nleri')
axes[1, 1].set_ylabel('Hisse FiyatÄ± ($)')
axes[1, 1].legend()
axes[1, 1].grid(True, alpha=0.3)

# Hata daÄŸÄ±lÄ±mÄ±
errors = y_test_inv.flatten() - test_pred_inv.flatten()
axes[2, 0].hist(errors, bins=50, alpha=0.7, color='skyblue', edgecolor='black')
axes[2, 0].set_title('Hata DaÄŸÄ±lÄ±mÄ± (Test Seti)', fontweight='bold')
axes[2, 0].set_xlabel('Tahmin HatasÄ± ($)')
axes[2, 0].set_ylabel('Frekans')
axes[2, 0].axvline(x=0, color='red', linestyle='--', linewidth=2)
axes[2, 0].grid(True, alpha=0.3)

# Metrik karÅŸÄ±laÅŸtÄ±rmasÄ±
metrics_names = ['MSE', 'MAE', 'RMSE', 'MAPE (%)']
train_values = [train_metrics['mse'], train_metrics['mae'], 
                train_metrics['rmse'], train_metrics['mape']]
val_values = [val_metrics['mse'], val_metrics['mae'], 
              val_metrics['rmse'], val_metrics['mape']]
test_values = [test_metrics['mse'], test_metrics['mae'], 
               test_metrics['rmse'], test_metrics['mape']]

x = np.arange(len(metrics_names))
width = 0.25

bars1 = axes[2, 1].bar(x - width, train_values, width, label='EÄŸitim', alpha=0.8)
bars2 = axes[2, 1].bar(x, val_values, width, label='Validasyon', alpha=0.8)
bars3 = axes[2, 1].bar(x + width, test_values, width, label='Test', alpha=0.8)

axes[2, 1].set_title('Metrik KarÅŸÄ±laÅŸtÄ±rmasÄ±', fontweight='bold')
axes[2, 1].set_xlabel('Metrikler')
axes[2, 1].set_ylabel('DeÄŸer')
axes[2, 1].set_xticks(x)
axes[2, 1].set_xticklabels(metrics_names)
axes[2, 1].legend()
axes[2, 1].grid(True, alpha=0.3)
axes[2, 1].set_yscale('log')

plt.tight_layout()
plt.show()

print_section("MULTI-STEP PREDICTION ANALÄ°ZÄ°")

print("ğŸ”® Ã‡ok adÄ±mlÄ± tahmin analizi...")

# 5 gÃ¼nlÃ¼k tahminleri analiz et
test_pred_multi = model.predict(X_test[-50:], verbose=0)  # Son 50 Ã¶rnek
test_pred_multi_inv = inverse_transform_predictions(test_pred_multi, scaler)
y_test_multi_inv = inverse_transform_predictions(y_test[-50:], scaler)

# Her gÃ¼n iÃ§in ayrÄ± metrikler
daily_metrics = []
for day in range(PREDICTION_DAYS):
    day_pred = test_pred_multi_inv[:, day]
    day_true = y_test_multi_inv[:, day]
    
    mae = mean_absolute_error(day_true, day_pred)
    rmse = np.sqrt(mean_squared_error(day_true, day_pred))
    mape = np.mean(np.abs((day_true - day_pred) / day_true)) * 100
    
    daily_metrics.append({'day': day+1, 'mae': mae, 'rmse': rmse, 'mape': mape})
    print(f"ğŸ“… GÃ¼n {day+1}: MAE={mae:.2f}, RMSE={rmse:.2f}, MAPE={mape:.2f}%")

# Multi-step tahmin gÃ¶rselleÅŸtirmesi
plt.figure(figsize=(15, 10))

# Ä°lk 10 Ã¶rnek iÃ§in 5 gÃ¼nlÃ¼k tahminleri gÃ¶ster
for i in range(min(5, len(test_pred_multi_inv))):
    plt.subplot(2, 3, i+1)
    days = range(1, PREDICTION_DAYS + 1)
    plt.plot(days, y_test_multi_inv[i], 'bo-', label='GerÃ§ek', linewidth=2, markersize=8)
    plt.plot(days, test_pred_multi_inv[i], 'ro-', label='Tahmin', linewidth=2, markersize=8)
    plt.title(f'Ã–rnek {i+1} - 5 GÃ¼nlÃ¼k Tahmin', fontweight='bold')
    plt.xlabel('GÃ¼n')
    plt.ylabel('Fiyat ($)')
    plt.legend()
    plt.grid(True, alpha=0.3)

# GÃ¼nlÃ¼k hata analizi
plt.subplot(2, 3, 6)
days = [m['day'] for m in daily_metrics]
maes = [m['mae'] for m in daily_metrics]
rmses = [m['rmse'] for m in daily_metrics]

plt.plot(days, maes, 'bo-', label='MAE', linewidth=2, markersize=8)
plt.plot(days, rmses, 'ro-', label='RMSE', linewidth=2, markersize=8)
plt.title('GÃ¼nlÃ¼k Hata Analizi', fontweight='bold')
plt.xlabel('Tahmin GÃ¼nÃ¼')
plt.ylabel('Hata')
plt.legend()
plt.grid(True, alpha=0.3)

plt.tight_layout()
plt.show()

print_section("GERÃ‡EK ZAMAN TAHMÄ°NÄ° Ã–RNEÄÄ°")

print("ğŸ”® Son verileri kullanarak gelecek 5 gÃ¼n tahmini...")

# En son 60 gÃ¼nlÃ¼k veriyi al
last_sequence = scaled_data[-LOOKBACK_DAYS:].reshape(1, LOOKBACK_DAYS, 1)

# Tahmin yap
future_prediction = model.predict(last_sequence, verbose=0)
future_prediction_inv = inverse_transform_predictions(future_prediction, scaler)

# Son gerÃ§ek fiyatlarÄ± gÃ¶ster
last_prices = stock_price[-10:]
print("\nğŸ“Š Son 10 gÃ¼nÃ¼n gerÃ§ek fiyatlarÄ±:")
for i, price in enumerate(last_prices, 1):
    print(f"   GÃ¼n -{10-i+1}: ${price:.2f}")

print(f"\nğŸ”® Gelecek 5 gÃ¼nÃ¼n tahminleri:")
for i, pred_price in enumerate(future_prediction_inv[0], 1):
    print(f"   GÃ¼n +{i}: ${pred_price:.2f}")

# Tahminleri gÃ¶rselleÅŸtir
plt.figure(figsize=(12, 6))

# GeÃ§miÅŸ verileri gÃ¶ster
past_days = range(-len(last_prices), 0)
future_days = range(1, PREDICTION_DAYS + 1)

plt.plot(past_days, last_prices, 'bo-', label='GerÃ§ek Fiyatlar', 
         linewidth=3, markersize=10, alpha=0.8)
plt.plot(future_days, future_prediction_inv[0], 'ro-', label='LSTM Tahminleri', 
         linewidth=3, markersize=10, alpha=0.8)

# BugÃ¼nÃ¼ iÅŸaretle
plt.axvline(x=0, color='gray', linestyle='--', linewidth=2, alpha=0.7)
plt.text(0.1, plt.ylim()[1]*0.9, 'BugÃ¼n', fontsize=12, fontweight='bold')

plt.title('Hisse Senedi Fiyat Tahmini - Son 10 GÃ¼n + Gelecek 5 GÃ¼n', 
          fontsize=14, fontweight='bold')
plt.xlabel('GÃ¼n')
plt.ylabel('Fiyat ($)')
plt.legend(fontsize=12)
plt.grid(True, alpha=0.3)
plt.show()

print_section("Ã–ZET VE SONUÃ‡LAR")

print("âœ… Bu LSTM Ã¶rneÄŸinde Ã¶ÄŸrendikleriniz:")
print("  1. ğŸ§  LSTM'in Vanilla RNN'den farklarÄ±")
print("  2. ğŸšª Gate mekanizmalarÄ±nÄ±n Ã§alÄ±ÅŸma prensibi")
print("  3. ğŸ“Š KarmaÅŸÄ±k zaman serisi verisiyle Ã§alÄ±ÅŸma")
print("  4. ğŸ—ï¸ Ã‡ok katmanlÄ± LSTM mimarisi tasarÄ±mÄ±")
print("  5. ğŸ”® Multi-step prediction (Ã§ok adÄ±mlÄ± tahmin)")
print("  6. ğŸ“ˆ GerÃ§ek zamanlÄ± tahmin uygulamasÄ±")
print("")
print("ğŸ’¡ LSTM'in avantajlarÄ± bu Ã¶rnekte gÃ¶rÃ¼ldÃ¼:")
print("  âœ… Uzun vadeli baÄŸÄ±mlÄ±lÄ±klarÄ± Ã¶ÄŸrenebilir")
print("  âœ… Gradient vanishing problemi olmaz")
print("  âœ… Kompleks zaman serilerinde baÅŸarÄ±lÄ±")
print("  âœ… Multi-step prediction yapabilir")
print("")
print("ğŸ“ˆ Model performansÄ±:")
print(f"  â€¢ Test MAE: {test_metrics['mae']:.2f}$")
print(f"  â€¢ Test MAPE: {test_metrics['mape']:.2f}%")
print(f"  â€¢ Model, ortalama {test_metrics['mape']:.1f}% hata ile tahmin yapÄ±yor")
print("")
print("ğŸ”„ Model iyileÅŸtirme Ã¶nerileri:")
print("  1. Daha fazla feature (teknik gÃ¶stergeler)")
print("  2. Attention mekanizmasÄ± ekleme")
print("  3. Ensemble modeller kullanma")
print("  4. Hiperparametre optimizasyonu")
print("")
print("ğŸ“š Sonraki dosya: 06_gru_example.py")
print("GRU (Gated Recurrent Unit) ile LSTM'i karÅŸÄ±laÅŸtÄ±racaÄŸÄ±z!")

print_section("âœ… LSTM Ã–RNEÄÄ° TAMAMLANDI!", char="-", single_line=True, width=35)
