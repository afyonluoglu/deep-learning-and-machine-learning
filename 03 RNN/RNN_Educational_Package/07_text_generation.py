"""
ğŸ”¤ METÄ°N ÃœRETÄ°MÄ° Ä°LE RNN Ã–ÄRENÄ°MÄ°
==================================

Bu dosya RNN'leri metin Ã¼retimi ile Ã¶ÄŸretir.
Character-level language model kullanarak RNN'lerin
nasÄ±l sequential pattern'leri Ã¶ÄŸrendiÄŸini gÃ¶sterir.

Ã–ÄŸreneceÄŸiniz konular:
1. Character-level text processing
2. One-hot encoding
3. Text generation with RNN
4. Temperature sampling
5. Model creativity control
"""

import os
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'
import numpy as np
import matplotlib.pyplot as plt
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense, Dropout
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import LearningRateScheduler
import random

print("=" * 60)
print("ğŸ”¤ METÄ°N ÃœRETÄ°MÄ° Ä°LE RNN Ã–ÄRENÄ°MÄ°")
print("=" * 60)

def print_section(title, char="=", width=50):
    print(f"\n{char*width}")
    print(f"ğŸ“‹ {title}")
    print(f"{char*width}")

print_section("Ã–RNEK METÄ°N HAZIRLIÄI")

# TÃ¼rkÃ§e Ã¶rnek metin - Yunus Emre'den
sample_text = """
miskince gel ey canlar bu canlara gaÅŸ olam
dost yoluna varÄ±cak yol dostlara gaÅŸ olam
gerek yÃ¼riyem tenha gÃ¶Ã§em Ä±ssÄ±z yerde
aÅŸk elinden Ã¶licem dostlara gaÅŸ olam

bu gÃ¶nÃ¼l ÅŸehr-i cananÄ±n kuÅŸu iken
nice olur ayrÄ± dÃ¼ÅŸem dostlara gaÅŸ olam
bu gÃ¶nÃ¼l dost daraÄŸÄ±nda bÃ¼lbÃ¼l iken
nice olur karakuÅŸa yar keremin gaÅŸ olam

bu baÅŸÄ±m kurbanÄ± olsun dostlarÄ±n hakkÄ±na
severem ben anlarÄ±n yÃ¼zÃ¼ suyu hakkÄ±na
uÅŸ gitmezem el Ã§ekip dostlarÄ±n yolundan
tut elim yunus miskin dostlara gaÅŸ olam
""".strip()

# Metni temizle ve kÃ¼Ã§Ã¼k harfe Ã§evir
text = sample_text.lower()
text = ''.join([char for char in text if char.isalpha() or char.isspace() or char in '.,!?'])

print("ğŸ“– Ã–rnek metin:")
print(text[:200] + "...")
print(f"\nğŸ“Š Metin istatistikleri:")
print(f"   Toplam karakter sayÄ±sÄ±: {len(text)}")
print(f"   Benzersiz karakter sayÄ±sÄ±: {len(set(text))}")

# Karakter setini oluÅŸtur
chars = sorted(list(set(text)))
char_to_int = {char: i for i, char in enumerate(chars)}
int_to_char = {i: char for i, char in enumerate(chars)}

n_chars = len(chars)
n_vocab = len(chars)

print(f"\nğŸ”¤ Karakter seti: {chars}")
print(f"ğŸ“Š Vocabulary boyutu: {n_vocab}")

print_section("VERÄ° HAZIRLAMA VE SEQUENCE OLUÅTURMA")

# Sequence parametreleri
seq_length = 40  # 40 karakterlik sequence'ler kullan
step = 3         # Her 3 karakterde bir yeni sequence baÅŸlat

print(f"âš™ï¸ Parametreler:")
print(f"   Sequence uzunluÄŸu: {seq_length}")
print(f"   AdÄ±m boyutu: {step}")

# Sequence'leri oluÅŸtur
sequences = []
next_chars = []

for i in range(0, len(text) - seq_length, step):
    sequences.append(text[i:i + seq_length])
    next_chars.append(text[i + seq_length])

print(f"ğŸ“Š Toplam {len(sequences)} sequence oluÅŸturuldu")

# Ä°lk birkaÃ§ sequence'i gÃ¶ster
print(f"\nğŸ” Ä°lk 3 sequence Ã¶rneÄŸi:")
for i in range(3):
    print(f"  Sequence {i+1}: '{sequences[i]}'")
    print(f"  Sonraki char: '{next_chars[i]}'")
    print()

# One-hot encoding iÃ§in veri hazÄ±rla
print("ğŸ”¢ One-hot encoding yapÄ±lÄ±yor...")

X = np.zeros((len(sequences), seq_length, n_vocab), dtype=np.bool_)
y = np.zeros((len(sequences), n_vocab), dtype=np.bool_)

for i, sequence in enumerate(sequences):
    for t, char in enumerate(sequence):
        X[i, t, char_to_int[char]] = 1
    y[i, char_to_int[next_chars[i]]] = 1

print(f"âœ… Encoding tamamlandÄ±!")
print(f"   X shape: {X.shape} (Ã¶rnekler, sequence_length, vocab_size)")
print(f"   y shape: {y.shape} (Ã¶rnekler, vocab_size)")

print_section("RNN MODELÄ° TASARIMI")

print("ğŸ—ï¸ Character-level RNN modeli oluÅŸturuluyor...")

model = Sequential([
    LSTM(128, input_shape=(seq_length, n_vocab), return_sequences=True),
    Dropout(0.2),
    LSTM(128),
    Dropout(0.2),
    Dense(n_vocab, activation='softmax')
])

# Learning rate scheduler
def lr_schedule(epoch):
    """Epoch'a gÃ¶re learning rate ayarlar"""
    if epoch < 10:
        return 0.01
    elif epoch < 20:
        return 0.005
    else:
        return 0.001

# Model derle
optimizer = Adam(learning_rate=0.01)
model.compile(loss='categorical_crossentropy', optimizer=optimizer)

print("âœ… Model hazÄ±rlandÄ±!")
print(f"\nğŸ“‹ MODEL Ã–ZETÄ°:")
model.summary()

print_section("METÄ°N ÃœRETME FONKSÄ°YONLARI")

def sample_with_temperature(predictions, temperature=1.0):
    """
    Temperature ile sampling yapar
    
    Args:
        predictions: Model tahminleri (probability distribution)
        temperature: YaratÄ±cÄ±lÄ±k kontrolÃ¼
                    - DÃ¼ÅŸÃ¼k (0.2-0.5): Muhafazakar, tekrarlanan
                    - Orta (0.8-1.2): Dengeli
                    - YÃ¼ksek (1.5-2.0): YaratÄ±cÄ±, rastgele
    
    Returns:
        SeÃ§ilen karakterin index'i
    """
    predictions = np.asarray(predictions).astype('float64')
    predictions = np.log(predictions + 1e-8) / temperature
    exp_preds = np.exp(predictions)
    predictions = exp_preds / np.sum(exp_preds)
    probas = np.random.multinomial(1, predictions, 1)
    return np.argmax(probas)

def generate_text(model, seed_text, length=200, temperature=1.0):
    """
    Verilen seed text ile yeni metin Ã¼retir
    
    Args:
        model: EÄŸitilmiÅŸ RNN modeli
        seed_text: BaÅŸlangÄ±Ã§ metni
        length: Ãœretilecek karakter sayÄ±sÄ±
        temperature: YaratÄ±cÄ±lÄ±k seviyesi
    
    Returns:
        Ãœretilen metin
    """
    generated = seed_text.lower()
    seed = seed_text.lower()
    
    for i in range(length):
        # Son seq_length karakteri al
        if len(seed) < seq_length:
            # Padding with spaces
            padded_seed = ' ' * (seq_length - len(seed)) + seed
        else:
            padded_seed = seed[-seq_length:]
        
        # One-hot encode
        x_pred = np.zeros((1, seq_length, n_vocab))
        for t, char in enumerate(padded_seed):
            if char in char_to_int:
                x_pred[0, t, char_to_int[char]] = 1
        
        # Tahmin yap
        predictions = model.predict(x_pred, verbose=0)[0]
        
        # Temperature ile sampling
        next_index = sample_with_temperature(predictions, temperature)
        next_char = int_to_char[next_index]
        
        generated += next_char
        seed = seed + next_char
    
    return generated

# FarklÄ± temperature'larÄ± demo et
def demonstrate_temperature():
    """FarklÄ± temperature deÄŸerlerini gÃ¶sterir"""
    
    print("ğŸŒ¡ï¸ TEMPERATURE Ã–RNEKLERÄ°:")
    print("-" * 40)
    
    seed = "miskince gel"
    temperatures = [0.2, 0.5, 1.0, 1.5, 2.0]
    
    for temp in temperatures:
        print(f"\nğŸŒ¡ï¸ Temperature: {temp}")
        if temp <= 0.5:
            print("   Beklenen: Muhafazakar, gÃ¼venli seÃ§imler")
        elif temp <= 1.2:
            print("   Beklenen: Dengeli, okunabilir")
        else:
            print("   Beklenen: YaratÄ±cÄ±, riskli")
        
        # Bu aÅŸamada model henÃ¼z eÄŸitilmediÄŸi iÃ§in demo Ã§Ä±ktÄ±sÄ±
        print(f"   Ã–rnek: '{seed}' + [model Ã¼retimi]")

demonstrate_temperature()

print_section("MODEL EÄÄ°TÄ°MÄ°")

print("ğŸš€ Model eÄŸitimi baÅŸlÄ±yor...")

# Training callbacks
lr_scheduler = LearningRateScheduler(lr_schedule)

class TextGenerationCallback(tf.keras.callbacks.Callback):
    """Her epoch sonunda Ã¶rnek metin Ã¼retir"""
    
    def __init__(self, seed_text="miskince"):
        self.seed_text = seed_text
    
    def on_epoch_end(self, epoch, logs=None):
        if epoch % 5 == 0:  # Her 5 epoch'ta bir
            print(f"\nğŸ“ Epoch {epoch+1} - Ã–rnek Ã¼retim:")
            generated = generate_text(self.model, self.seed_text, 100, temperature=0.8)
            print(f"   '{generated[:80]}...'")

# Callbacks
text_callback = TextGenerationCallback()

# Model eÄŸitimi
history = model.fit(
    X, y,
    batch_size=64,
    epochs=30,
    callbacks=[lr_scheduler, text_callback],
    verbose=1
)

print("âœ… EÄŸitim tamamlandÄ±!")

print_section("METÄ°N ÃœRETME DENEYÄ°MLERÄ°")

print("ğŸ¨ FarklÄ± temperature'larla metin Ã¼retimi:")

seed_texts = ["miskince gel", "bu gÃ¶nÃ¼l", "dost yoluna"]
temperatures = [0.3, 0.8, 1.5]

results = []

for seed in seed_texts:
    print(f"\nğŸŒ± Seed: '{seed}'")
    print("-" * 30)
    
    for temp in temperatures:
        print(f"\nğŸŒ¡ï¸ Temperature: {temp}")
        generated = generate_text(model, seed, 150, temperature=temp)
        print(f"ğŸ“ Ãœretilen metin:")
        print(f"   {generated}")
        
        results.append({
            'seed': seed,
            'temperature': temp,
            'generated': generated
        })

print_section("METÄ°N KALÄ°TE ANALÄ°ZÄ°")

def analyze_text_quality(generated_text, original_chars):
    """Ãœretilen metnin kalitesini analiz eder"""
    
    # Karakter Ã§eÅŸitliliÄŸi
    unique_chars = len(set(generated_text))
    diversity = unique_chars / len(original_chars)
    
    # Kelime sayÄ±sÄ±
    words = generated_text.split()
    word_count = len(words)
    avg_word_length = np.mean([len(word) for word in words]) if words else 0
    
    # Tekrar analizi
    char_counts = {}
    for char in generated_text:
        char_counts[char] = char_counts.get(char, 0) + 1
    
    # En sÄ±k kullanÄ±lan karakterler
    most_common = sorted(char_counts.items(), key=lambda x: x[1], reverse=True)[:5]
    
    return {
        'length': len(generated_text),
        'unique_chars': unique_chars,
        'diversity': diversity,
        'word_count': word_count,
        'avg_word_length': avg_word_length,
        'most_common_chars': most_common
    }

print("ğŸ“Š METÄ°N KALÄ°TE ANALÄ°ZÄ°:")
print("-" * 30)

# Orijinal metin analizi
original_analysis = analyze_text_quality(text, chars)
print(f"ğŸ“– Orijinal metin:")
print(f"   Uzunluk: {original_analysis['length']}")
print(f"   Benzersiz karakter: {original_analysis['unique_chars']}")
print(f"   Ã‡eÅŸitlilik: {original_analysis['diversity']:.3f}")
print(f"   Kelime sayÄ±sÄ±: {original_analysis['word_count']}")
print(f"   Ort. kelime uzunluÄŸu: {original_analysis['avg_word_length']:.1f}")

# Ãœretilen metinlerin analizi
print(f"\nğŸ“ Ãœretilen metinler:")
for i, result in enumerate(results[:3]):  # Ä°lk 3 sonuÃ§
    analysis = analyze_text_quality(result['generated'], chars)
    print(f"\n   Ã–rnek {i+1} (T={result['temperature']}):")
    print(f"     Ã‡eÅŸitlilik: {analysis['diversity']:.3f}")
    print(f"     Kelime sayÄ±sÄ±: {analysis['word_count']}")
    print(f"     Ort. kelime uzunluÄŸu: {analysis['avg_word_length']:.1f}")

print_section("GÃ–RSELLEÅTÄ°RME VE ANALÄ°Z")

# Training loss gÃ¶rselleÅŸtirmesi
plt.figure(figsize=(15, 10))

# Loss grafiÄŸi
plt.subplot(2, 2, 1)
plt.plot(history.history['loss'], 'b-', linewidth=2)
plt.title('ğŸ“‰ Model EÄŸitim Loss', fontweight='bold')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.grid(True, alpha=0.3)

# Karakter frekans analizi
plt.subplot(2, 2, 2)
char_freq = {}
for char in text:
    char_freq[char] = char_freq.get(char, 0) + 1

# En sÄ±k 10 karakter
top_chars = sorted(char_freq.items(), key=lambda x: x[1], reverse=True)[:10]
chars_list, freqs_list = zip(*top_chars)

plt.bar(range(len(chars_list)), freqs_list, alpha=0.7)
plt.title('ğŸ“Š En SÄ±k KullanÄ±lan Karakterler', fontweight='bold')
plt.xlabel('Karakterler')
plt.ylabel('Frekans')
plt.xticks(range(len(chars_list)), chars_list)
plt.grid(True, alpha=0.3)

# Temperature karÅŸÄ±laÅŸtÄ±rmasÄ±
plt.subplot(2, 2, 3)
temp_values = [0.3, 0.8, 1.5]
diversities = []

for temp in temp_values:
    # Her temperature iÃ§in diversity hesapla
    sample_text = generate_text(model, "miskince", 200, temperature=temp)
    analysis = analyze_text_quality(sample_text, chars)
    diversities.append(analysis['diversity'])

plt.plot(temp_values, diversities, 'ro-', linewidth=2, markersize=8)
plt.title('ğŸŒ¡ï¸ Temperature vs Ã‡eÅŸitlilik', fontweight='bold')
plt.xlabel('Temperature')
plt.ylabel('Karakter Ã‡eÅŸitliliÄŸi')
plt.grid(True, alpha=0.3)

# Model karmaÅŸÄ±klÄ±ÄŸÄ±
plt.subplot(2, 2, 4)
layers = ['LSTM-1', 'Dropout-1', 'LSTM-2', 'Dropout-2', 'Dense']
params = [128*4*128, 0, 128*4*128, 0, 128*n_vocab]  # YaklaÅŸÄ±k parametre sayÄ±larÄ±

plt.bar(layers, params, alpha=0.7, color=['blue', 'gray', 'blue', 'gray', 'green'])
plt.title('ğŸ—ï¸ Model Katman Parametreleri', fontweight='bold')
plt.xlabel('Katmanlar')
plt.ylabel('Parametre SayÄ±sÄ±')
plt.xticks(rotation=45)
plt.grid(True, alpha=0.3)

plt.tight_layout()
plt.show()

print_section("Ä°NTERAKTÄ°F METÄ°N ÃœRETME")

def interactive_text_generation():
    """KullanÄ±cÄ± ile interaktif metin Ã¼retme"""
    
    print("ğŸ® Ä°NTERAKTÄ°F METÄ°N ÃœRETME")
    print("-" * 30)
    print("Ã–nerilen seed'ler:")
    suggestions = ["miskince gel", "bu gÃ¶nÃ¼l", "dost yoluna", "severem ben"]
    for i, suggestion in enumerate(suggestions, 1):
        print(f"  {i}. '{suggestion}'")
    
    print("\nğŸ’¡ KullanÄ±m Ã¶rnekleri:")
    print("  - DÃ¼ÅŸÃ¼k temperature (0.2-0.5): GÃ¼venli, okunabilir")
    print("  - Orta temperature (0.8-1.2): Dengeli, yaratÄ±cÄ±")
    print("  - YÃ¼ksek temperature (1.5-2.0): Ã‡ok yaratÄ±cÄ±, riskli")
    
    # Demo iÃ§in Ã¶rnekler
    demo_examples = [
        {"seed": "miskince gel", "temp": 0.5, "length": 100},
        {"seed": "bu gÃ¶nÃ¼l", "temp": 1.0, "length": 120},
        {"seed": "dost yoluna", "temp": 1.5, "length": 80}
    ]
    
    print(f"\nğŸ¯ DEMO Ã–RNEKLERÄ°:")
    for i, example in enumerate(demo_examples, 1):
        print(f"\nÃ–rnek {i}:")
        print(f"  Seed: '{example['seed']}'")
        print(f"  Temperature: {example['temp']}")
        print(f"  Uzunluk: {example['length']}")
        
        generated = generate_text(model, example['seed'], example['length'], example['temp'])
        print(f"  SonuÃ§: '{generated[:60]}...'")

interactive_text_generation()

print_section("Ã–ZET VE SONUÃ‡LAR")

print("âœ… Bu metin Ã¼retimi Ã¶rneÄŸinde Ã¶ÄŸrendikleriniz:")
print("  1. ğŸ”¤ Character-level text processing")
print("  2. ğŸ”¢ One-hot encoding ve vocabulary oluÅŸturma")
print("  3. ğŸ§  RNN ile sequence modeling")
print("  4. ğŸŒ¡ï¸ Temperature sampling ve creativity control")
print("  5. ğŸ“Š Text quality analysis")
print("  6. ğŸ® Interactive text generation")
print("")
print("ğŸ’¡ RNN'in metin Ã¼retimindeki yetenekleri:")
print("  âœ… Sequential pattern learning")
print("  âœ… Context-aware generation")
print("  âœ… Controllable creativity")
print("  âœ… Language modeling")
print("")
print("ğŸ¨ Temperature etkisi:")
print("  â€¢ DÃ¼ÅŸÃ¼k temperature â†’ Muhafazakar, tutarlÄ±")
print("  â€¢ YÃ¼ksek temperature â†’ YaratÄ±cÄ±, riskli")
print("  â€¢ Optimal deÄŸer problem ve context'e baÄŸlÄ±")
print("")
print("ğŸš€ Ä°yileÅŸtirme Ã¶nerileri:")
print("  1. Daha bÃ¼yÃ¼k dataset kullanÄ±n")
print("  2. Word-level modeling deneyin")
print("  3. Attention mechanism ekleyin")
print("  4. Beam search kullanÄ±n")
print("  5. Fine-tuning ile Ã¶zelleÅŸtirin")
print("")
print("ğŸ“š Sonraki dosya: 08_sentiment_analysis.py")
print("RNN ile duygu analizi yapacaÄŸÄ±z!")

print("\n" + "=" * 60)
print("âœ… METÄ°N ÃœRETÄ°MÄ° Ã–RNEÄÄ° TAMAMLANDI!")
print("=" * 60)