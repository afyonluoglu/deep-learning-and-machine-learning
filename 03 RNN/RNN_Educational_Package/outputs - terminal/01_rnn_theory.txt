===========================================================================
ğŸ§  RNN TEORÄ°SÄ° VE TEMEL KAVRAMLAR
===========================================================================


==================================================
ğŸ“‹ RNN NEDÄ°R?
==================================================

Recurrent Neural Network (RNN):
â€¢ Zaman serilerini iÅŸlemek iÃ§in tasarlanmÄ±ÅŸ Ã¶zel sinir aÄŸÄ±
â€¢ GeÃ§miÅŸ bilgileri 'hatÄ±rlayarak' tahmin yapar
â€¢ Sequential (sÄ±ralÄ±) verilerle Ã§alÄ±ÅŸÄ±r

==================================================
ğŸ”„ RNN Ã‡ALIÅMA PRENSÄ°BÄ°
==================================================

1. Her zaman adÄ±mÄ±nda:
   - Mevcut giriÅŸ (x_t)
   - Ã–nceki hidden state (h_t-1)
   - Yeni hidden state hesaplanÄ±r (h_t)

2. FormÃ¼l:
   h_t = tanh(W_hh * h_t-1 + W_xh * x_t + b)
   y_t = W_hy * h_t + b_y

==================================================
ğŸ“Š BASIT RNN Ã–RNEÄÄ° - MANUEL UYGULAMA
==================================================



ğŸ›ï¸ PARAMETRIK AYARLAR
--------------------------------------------------

âœ… Hidden Size : 13
âœ… Input Size  : 2
âœ… Time Steps  : 6
âœ… Weight Scale: 0.2
â¡ï¸ AÄŸÄ±rlÄ±k matrisleri oluÅŸturuldu (boyutlar: W_hh=(13, 13), W_xh=(13, 2))

ğŸŸ¢ GiriÅŸ dizisi (6 zaman adÄ±mÄ±):
  t0: [-0.21712612,  0.69973454]
  t1: [ 0.74941602,  0.14937053]
  t2: [ 0.57710027, -0.13485635]
  t3: [-0.48533585, -0.64289126]
  t4: [-0.43963307, -0.38667404]
  t5: [-0.82859755,  0.29052910]

==================================================
ğŸ” ADIM ADIM RNN HESAPLAMA:
==================================================

BaÅŸlangÄ±Ã§ hidden states: [0. 0. 0. 0. 0.] ... (13 nÃ¶ron)
t0: x_t = [-0.21712612,  0.69973454], h_t = [-0.09149701,  0.02463162,  0.02390287, -0.03408783, -0.09982437] ... (ilk 5 nÃ¶ron)
t1: x_t = [ 0.74941602,  0.14937053], h_t = [-0.20270418, -0.07957355,  0.10906404,  0.15271248,  0.23508044] ... (ilk 5 nÃ¶ron)
t2: x_t = [ 0.57710027, -0.13485635], h_t = [-0.10798933,  0.00757320,  0.15417384,  0.07508851,  0.13263846] ... (ilk 5 nÃ¶ron)
t3: x_t = [-0.48533585, -0.64289126], h_t = [ 0.20218989, -0.00979547, -0.00406972, -0.11034413, -0.18572947] ... (ilk 5 nÃ¶ron)
t4: x_t = [-0.43963307, -0.38667404], h_t = [ 0.21616049, -0.10842690, -0.20838361, -0.06609838, -0.14018178] ... (ilk 5 nÃ¶ron)
t5: x_t = [-0.82859755,  0.29052910], h_t = [ 0.11132193,  0.16597711, -0.13021565, -0.10262410, -0.20577784] ... (ilk 5 nÃ¶ron)

==================================================
ğŸ“ˆ GÄ°ZLÄ° DURUMLARIN GÃ–RSELLEÅTÄ°RÄ°LMESÄ°
==================================================

ğŸ“Š Grafikte gÃ¶sterilen nÃ¶ron sayÄ±sÄ±: 10 / 13



ğŸ§ª PARAMETRÄ°K DENEY SÄ°STEMÄ°
--------------------------------------------------

YukarÄ±daki parametreleri deÄŸiÅŸtirerek farklÄ± deneyler yapabilirsiniz!



ğŸ”§ NASIL FARKLI DURUMLAR DENEYEBÄ°LÄ°RÄ°M?
--------------------------------------------------

1. DosyanÄ±n baÅŸÄ±ndaki parametreleri deÄŸiÅŸtirin:
   â€¢ HIDDEN_SIZE  = 5, 10, 20, 50  (farklÄ± deÄŸerler deneyin)
   â€¢ TIME_STEPS   = 4, 8, 15, 20   (farklÄ± zaman aralÄ±klarÄ±)
   â€¢ WEIGHT_SCALE = 0.01, 0.1, 0.5 (aÄŸÄ±rlÄ±k bÃ¼yÃ¼klÃ¼kleri)

2. Kodu tekrar Ã§alÄ±ÅŸtÄ±rÄ±n ve sonuÃ§larÄ± karÅŸÄ±laÅŸtÄ±rÄ±n.


==================================================
ğŸ¯ DENEYÄ°M Ã–NERÄ°LERÄ°:
==================================================

â€¢ Hidden Size 2 - 20      : Hangi daha iyi Ã¶ÄŸrenir?
â€¢ Time Steps 4 - 15       : Uzun veya kÄ±sa diziler
â€¢ Weight Scale 0.01 vs 0.5: AÄŸÄ±rlÄ±k etkisi

==================================================
ğŸ“Š MEVCUT DENEY SONUÃ‡LARI:
==================================================

âœ“ Hidden Size  : 13
âœ“ Time Steps   : 6
âœ“ Son Hidden State ortalama: -0.0582
âœ“ Hidden State deÄŸiÅŸkenliÄŸi: 0.0518
âœ“ Maksimum aktivasyon      : 0.4194

==================================================
ğŸ“ˆ OTOMATÄ°K PERFORMANS ANALÄ°ZÄ°:
==================================================

ğŸ”¹ HafÄ±za KararlÄ±lÄ±ÄŸÄ±: 0.0518
   (DÃ¼ÅŸÃ¼k = kararlÄ±, YÃ¼ksek = deÄŸiÅŸken)
ğŸ”¹ Aktivasyon GÃ¼cÃ¼: 0.1394
   (Ã‡ok dÃ¼ÅŸÃ¼k = Ã¶ÄŸrenme zor, Ã‡ok yÃ¼ksek = patlama riski)
ğŸ”¹ GiriÅŸ Hassasiyeti: 0.3768
   (YÃ¼ksek = Ã§eÅŸitli giriÅŸ desenleri)

==================================================
ğŸ’¡ PERFORMANS DEÄERLENDÄ°RMESÄ°:
==================================================

âœ… Aktivasyon dengeli gÃ¶rÃ¼nÃ¼yor
âœ… Hidden state kararlÄ±
Bir tuÅŸa basÄ±nÄ±z...



ğŸ¯ HIDDEN STATE'Ä°N FAYDASINI GÃ–STEREN Ã–RNEKLER
----------------------------------------------------------------------


==================================================
    ğŸ“‹ Ã–RNEK 1: DESEN TANIMA
==================================================

Diyelim ki ÅŸu sÄ±rayla sayÄ±lar gelsin: [1, 0, 1, 0]
Desen: 1 -> 0 -> 1 -> 0 (deÄŸiÅŸken desen)

t0: GiriÅŸ=[1. 0.] -> Hidden State: -0.14961562, -0.16172942,  0.06812471,  0.16394370,  0.28278524 ... (ilk 5 nÃ¶ron)
     En aktif nÃ¶ron: 5 (Bu nÃ¶ron geÃ§miÅŸi 'hatÄ±rlÄ±yor')
t1: GiriÅŸ=[0. 1.] -> Hidden State: -0.21663071,  0.11340465,  0.19995812, -0.01430364, -0.10633838 ... (ilk 5 nÃ¶ron)
     En aktif nÃ¶ron: 0 (Bu nÃ¶ron geÃ§miÅŸi 'hatÄ±rlÄ±yor')
t2: GiriÅŸ=[1. 0.] -> Hidden State: -0.19598122, -0.24106619,  0.16744805,  0.15327664,  0.28382123 ... (ilk 5 nÃ¶ron)
     En aktif nÃ¶ron: 5 (Bu nÃ¶ron geÃ§miÅŸi 'hatÄ±rlÄ±yor')
t3: GiriÅŸ=[0. 1.] -> Hidden State: -0.25041174,  0.09769502,  0.17490998,  0.00584659, -0.16960089 ... (ilk 5 nÃ¶ron)
     En aktif nÃ¶ron: 8 (Bu nÃ¶ron geÃ§miÅŸi 'hatÄ±rlÄ±yor')

ğŸ” ANALÄ°Z:
Hidden state'in deÄŸiÅŸimi, RNN'in Ã¶nceki giriÅŸleri 'hatÄ±rladÄ±ÄŸÄ±nÄ±' gÃ¶sterir!
Her adÄ±mda sadece o anki giriÅŸ deÄŸil, geÃ§miÅŸ giriÅŸler de etkili olur.
Bir tuÅŸa basÄ±nÄ±z...


==================================================
    ğŸ“‹ Ã–RNEK 2: GERÃ‡EK RNN EÄÄ°TÄ°MÄ° VE TAHMÄ°N
==================================================

RNN'i eÄŸitelim ve baÅŸarÄ±sÄ±nÄ± Ã¶lÃ§elim!


ğŸ¯ EÄŸitim veri seti oluÅŸturuluyor...
--------------------------------------------------

âœ… 50 eÄŸitim sekansÄ± oluÅŸturuldu (her biri 5 adÄ±m)
   - 30 azalan desen
   - 20 artan desen
   Ä°lk 5 sekans Ã¶rneÄŸi:
Training sequence 1:   1.2494,   0.8642,   0.4790,   0.0938,  -0.2914      Training target 1:  -0.6766
Training sequence 2:   1.6784,   1.3988,   1.1192,   0.8396,   0.5600      Training target 2:   0.2804
Training sequence 3:   0.9872,   0.8404,   0.6936,   0.5468,   0.4000      Training target 3:   0.2532
Training sequence 4:   0.8697,   0.5098,   0.1500,  -0.2099,  -0.5697      Training target 4:  -0.9296
Training sequence 5:   1.5213,   1.2089,   0.8965,   0.5841,   0.2717      Training target 5:  -0.0408

ğŸ¯ Test Dizisi  : 1.4,  1.1,  0.9,  0.6,  0.4 -> ???
   Beklenen sonraki deÄŸer: 0.1


ğŸ§  Creaating RNN Model...
--------------------------------------------------

âœ… Model created:
   Hidden Size   : 16
   Learning Rate : 0.05
   Weight matrices initialized (Xavier)


ğŸ“ Start training...
--------------------------------------------------

Epochs    : 40
Batch Size: 10

Epoch  1: Loss=5.4037, Test Prediction=0.352, Error=0.252
Epoch  6: Loss=0.1807, Test Prediction=0.245, Error=0.145
Epoch 11: Loss=0.1042, Test Prediction=0.078, Error=0.022
Epoch 16: Loss=0.0966, Test Prediction=0.052, Error=0.048
Epoch 21: Loss=0.0904, Test Prediction=0.052, Error=0.048
Epoch 26: Loss=0.0845, Test Prediction=0.054, Error=0.046
Epoch 31: Loss=0.0791, Test Prediction=0.057, Error=0.043
Epoch 36: Loss=0.0741, Test Prediction=0.059, Error=0.041
Epoch 40: Loss=0.0704, Test Prediction=0.062, Error=0.038

ğŸ¯ Training completed.


ğŸ“Š Result Analysis:
--------------------------------------------------

ğŸ”¹ Test Sequence  : 1.4,  1.1,  0.9,  0.6,  0.4
ğŸ”¹ Expected Value : 0.1
ğŸ”¹ RNN Prediction : 0.062
ğŸ”¹ Absolute Error : 0.038
ğŸ”¹ Error Rate     : 38.4%


ğŸ“ˆ Training Progress:
--------------------------------------------------

ğŸ”¹ Initial Loss   : 5.4037
ğŸ”¹ Final Loss     : 0.0704
ğŸ”¹ Improvement    : 98.7%

ğŸ† GREAT RESULT!
   RNN pattern successfully learned!

ğŸ† GREAT RESULT!
   RNN pattern successfully learned!

==================================================
ğŸ¯ ADDITIONAL TEST PATTERNS:
==================================================

Test 1: 2.0, 1.7, 1.4, 1.1, 0.8 -> Expected: 0.5, Prediction: 0.581, Error: 0.081
Test 2: 0.5, 0.7, 0.9, 1.1, 1.3 -> Expected: 1.5, Prediction: 1.826, Error: 0.326
Test 3: 1.0, 1.4, 1.9, 2.3, 2.8 -> Expected: 3.2, Prediction: 3.415, Error: 0.215


ğŸ“Š General Success Report:
--------------------------------------------------

ğŸ”¹ Average Error           : 0.165
ğŸ”¹ 1st Test Success Level  : ğŸ† Excellent
ğŸ”¹ 2nd Test Success Level  : âš ï¸  Average
ğŸ”¹ 3rd Test Success Level  : âš ï¸  Average
ğŸ”¹ Number of Tests        : 3
ğŸ‘ RNN learned the pattern at a reasonable level

ğŸ’¡ Training Details:
-------------------------
âœ…  Trained on 50 different patterns
âœ…  40 epochs of training completed
âœ…  Loss reduced by % 99
âœ…  Real backpropagation simulated
âœ…  Multiple pattern recognition achieved