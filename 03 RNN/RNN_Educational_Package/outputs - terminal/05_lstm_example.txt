################################################################################
ğŸ”¤ LSTM Ã–RNEÄÄ° - UZUN KISA SÃœRELÄ° HAFIZA
################################################################################
=======================================================
ğŸ“‹ LSTM TEORÄ°SÄ° VE VANILLA RNN KARÅILAÅTIRMASI
=======================================================
ğŸ§  LSTM vs Vanilla RNN:
-----------------------------------
Vanilla RNN Problemleri:
  âŒ Vanishing Gradient Problem
  âŒ Uzun vadeli baÄŸÄ±mlÄ±lÄ±klarÄ± Ã¶ÄŸrenemez
  âŒ Gradyanlar kaybolur/patlar

LSTM Ã‡Ã¶zÃ¼mleri:
  âœ… Cell State ile uzun vadeli hafÄ±za
  âœ… Gate mekanizmalarÄ± ile kontrollÃ¼ bilgi akÄ±ÅŸÄ±
  âœ… Gradyan akÄ±ÅŸÄ±nÄ± korur
  âœ… Selektif unutma ve hatÄ±rlama
=======================================================
ğŸ“‹ LSTM GATE MEKANÄ°ZMALARI
=======================================================
ğŸšª Gate AÃ§Ä±klamalarÄ±:
--------------------
1. ğŸ—‘ï¸ Forget Gate: Hangi bilgilerin Cell State'den silineceÄŸini karar verir
2. ğŸ“¥ Input Gate: Hangi yeni bilgilerin Cell State'e ekleneceÄŸini karar verir
3. ğŸ§  Cell State: Uzun vadeli hafÄ±zayÄ± saklar
4. ğŸ“¤ Output Gate: Cell State'in hangi kÄ±smÄ±nÄ±n Ã§Ä±ktÄ± olacaÄŸÄ±nÄ± karar verir
=======================================================
ğŸ“‹ PRATIK Ã–RNEK: HÄ°SSE SENEDÄ° FÄ°YAT TAHMÄ°NÄ°
=======================================================
ğŸ“Š KarmaÅŸÄ±k hisse senedi verisi oluÅŸturuluyor...
ğŸ“Š Veri istatistikleri:
   Toplam gÃ¼n sayÄ±sÄ±: 1000
   Ortalama fiyat: $151.82
   Min fiyat: $75.76
   Max fiyat: $236.26
   Standart sapma: $33.58
=======================================================
ğŸ“‹ VERÄ° Ã–N Ä°ÅLEME VE HAZIRLAMA
=======================================================
âš™ï¸ Parametre ayarlarÄ±:
   Geriye bakÄ±ÅŸ gÃ¼nleri: 60
   Tahmin gÃ¼nleri: 5
ğŸ“ Veri ÅŸekilleri:
   X: (936, 60, 1) (Ã¶rnekler, zaman_adÄ±mlarÄ±, Ã¶zellikler)
   y: (936, 5) (Ã¶rnekler, tahmin_gÃ¼nleri)
ğŸ“Š Veri bÃ¶lÃ¼mlemesi:
   EÄŸitim: 655 Ã¶rnek (70.0%)
   Validasyon: 140 Ã¶rnek (15.0%)
   Test: 141 Ã¶rnek (15.1%)
=======================================================
ğŸ“‹ LSTM MODELÄ° TASARIMI
=======================================================
ğŸ—ï¸ GeliÅŸmiÅŸ LSTM modeli oluÅŸturuluyor...
Model: LSTM (units=100) x2, Dropout: 0.23-> LSTM (units=50), Dropout: 0.23 -> Dense (50), Dropout: 0.15 -> Dense (25) -> Dense (5)
âœ… Model hazÄ±rlandÄ±!

ğŸ“‹ MODEL Ã–ZETÄ°:
Model: "sequential"
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Layer (type)                         â”ƒ Output Shape                â”ƒ         Param # â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚ lstm (LSTM)                          â”‚ (None, 60, 100)             â”‚          40,800 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ dropout (Dropout)                    â”‚ (None, 60, 100)             â”‚               0 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ lstm_1 (LSTM)                        â”‚ (None, 60, 100)             â”‚          80,400 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ dropout_1 (Dropout)                  â”‚ (None, 60, 100)             â”‚               0 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ lstm_2 (LSTM)                        â”‚ (None, 50)                  â”‚          30,200 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ dropout_2 (Dropout)                  â”‚ (None, 50)                  â”‚               0 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ dense (Dense)                        â”‚ (None, 50)                  â”‚           2,550 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ dropout_3 (Dropout)                  â”‚ (None, 50)                  â”‚               0 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ dense_1 (Dense)                      â”‚ (None, 25)                  â”‚           1,275 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ dense_2 (Dense)                      â”‚ (None, 5)                   â”‚             130 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
 Total params: 155,355 (606.86 KB)
 Trainable params: 155,355 (606.86 KB)
 Non-trainable params: 0 (0.00 B)
=======================================================
ğŸ“‹ MODEL EÄÄ°TÄ°MÄ°
=======================================================
ğŸš€ LSTM modeli eÄŸitiliyor...
Epoch 1/100
21/21 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 3s 42ms/step - loss: 0.0643 - mae: 0.2036 - val_loss: 0.0514 - val_mae: 0.1955 - learning_rate: 0.0010
Epoch 2/100
21/21 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 1s 31ms/step - loss: 0.0276 - mae: 0.1341 - val_loss: 0.0327 - val_mae: 0.1491 - learning_rate: 0.0010
Epoch 3/100
21/21 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 1s 31ms/step - loss: 0.0224 - mae: 0.1210 - val_loss: 0.0258 - val_mae: 0.1308 - learning_rate: 0.0010
Epoch 4/100
21/21 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 1s 31ms/step - loss: 0.0206 - mae: 0.1167 - val_loss: 0.0254 - val_mae: 0.1302 - learning_rate: 0.0010
Epoch 5/100
21/21 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 1s 31ms/step - loss: 0.0185 - mae: 0.1107 - val_loss: 0.0253 - val_mae: 0.1314 - learning_rate: 0.0010
Epoch 6/100
21/21 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 1s 31ms/step - loss: 0.0111 - mae: 0.0843 - val_loss: 0.0059 - val_mae: 0.0615 - learning_rate: 0.0010
Epoch 7/100
21/21 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 1s 30ms/step - loss: 0.0091 - mae: 0.0750 - val_loss: 0.0066 - val_mae: 0.0655 - learning_rate: 0.0010
Epoch 8/100
21/21 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 1s 30ms/step - loss: 0.0079 - mae: 0.0711 - val_loss: 0.0066 - val_mae: 0.0660 - learning_rate: 0.0010
Epoch 9/100
21/21 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 1s 30ms/step - loss: 0.0075 - mae: 0.0688 - val_loss: 0.0091 - val_mae: 0.0798 - learning_rate: 0.0010
Epoch 10/100
21/21 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 1s 30ms/step - loss: 0.0073 - mae: 0.0682 - val_loss: 0.0067 - val_mae: 0.0664 - learning_rate: 0.0010
Epoch 11/100
21/21 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 1s 30ms/step - loss: 0.0071 - mae: 0.0668 - val_loss: 0.0080 - val_mae: 0.0735 - learning_rate: 0.0010
Epoch 12/100
21/21 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 1s 30ms/step - loss: 0.0068 - mae: 0.0655 - val_loss: 0.0082 - val_mae: 0.0751 - learning_rate: 0.0010
Epoch 13/100
21/21 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 1s 30ms/step - loss: 0.0065 - mae: 0.0637 - val_loss: 0.0071 - val_mae: 0.0686 - learning_rate: 0.0010
Epoch 14/100
21/21 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 1s 30ms/step - loss: 0.0066 - mae: 0.0643 - val_loss: 0.0064 - val_mae: 0.0643 - learning_rate: 0.0010
Epoch 15/100
21/21 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 1s 31ms/step - loss: 0.0065 - mae: 0.0640 - val_loss: 0.0102 - val_mae: 0.0859 - learning_rate: 0.0010
Epoch 16/100
19/21 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 27ms/step - loss: 0.0059 - mae: 0.0608
Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.
21/21 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 1s 31ms/step - loss: 0.0060 - mae: 0.0615 - val_loss: 0.0100 - val_mae: 0.0834 - learning_rate: 0.0010
âœ… EÄŸitim tamamlandÄ±!
=======================================================
ğŸ“‹ MODEL DEÄERLENDÄ°RME
=======================================================
ğŸ”® Tahminler hesaplanÄ±yor...

ğŸ“Š EÄŸitim Metrikleri:
   MSE :  143.357537
   MAE :  9.6482
   RMSE: 11.9732
   MAPE: 7.06%

ğŸ“Š Validasyon Metrikleri:
   MSE :  157.980597
   MAE :  10.1369
   RMSE: 12.5690
   MAPE: 5.24%

ğŸ“Š Test Metrikleri:
   MSE :  117.130984
   MAE :  8.5055
   RMSE: 10.8227
   MAPE: 4.48%
=======================================================
ğŸ“‹ SONUÃ‡LARI GÃ–RSELLEÅTÄ°RME
=======================================================
=======================================================
ğŸ“‹ MULTI-STEP PREDICTION ANALÄ°ZÄ°
=======================================================
ğŸ”® Ã‡ok adÄ±mlÄ± tahmin analizi...
ğŸ“… GÃ¼n 1: MAE=8.12, RMSE=10.16, MAPE=4.52%
ğŸ“… GÃ¼n 2: MAE=8.25, RMSE=10.50, MAPE=4.62%
ğŸ“… GÃ¼n 3: MAE=8.00, RMSE=10.23, MAPE=4.46%
ğŸ“… GÃ¼n 4: MAE=8.92, RMSE=11.10, MAPE=4.97%
ğŸ“… GÃ¼n 5: MAE=9.49, RMSE=11.73, MAPE=5.26%
=======================================================
ğŸ“‹ GERÃ‡EK ZAMAN TAHMÄ°NÄ° Ã–RNEÄÄ°
=======================================================
ğŸ”® Son verileri kullanarak gelecek 5 gÃ¼n tahmini...

ğŸ“Š Son 10 gÃ¼nÃ¼n gerÃ§ek fiyatlarÄ±:
   GÃ¼n -10: $188.50
   GÃ¼n -9: $195.81
   GÃ¼n -8: $200.81
   GÃ¼n -7: $208.43
   GÃ¼n -6: $206.53
   GÃ¼n -5: $205.55
   GÃ¼n -4: $213.92
   GÃ¼n -3: $204.51
   GÃ¼n -2: $195.84
   GÃ¼n -1: $202.47

ğŸ”® Gelecek 5 gÃ¼nÃ¼n tahminleri:
   GÃ¼n +1: $194.89
   GÃ¼n +2: $191.39
   GÃ¼n +3: $190.15
   GÃ¼n +4: $191.95
   GÃ¼n +5: $189.69
=======================================================
ğŸ“‹ Ã–ZET VE SONUÃ‡LAR
=======================================================
âœ… Bu LSTM Ã¶rneÄŸinde Ã¶ÄŸrendikleriniz:
  1. ğŸ§  LSTM'in Vanilla RNN'den farklarÄ±
  2. ğŸšª Gate mekanizmalarÄ±nÄ±n Ã§alÄ±ÅŸma prensibi
  3. ğŸ“Š KarmaÅŸÄ±k zaman serisi verisiyle Ã§alÄ±ÅŸma
  4. ğŸ—ï¸ Ã‡ok katmanlÄ± LSTM mimarisi tasarÄ±mÄ±
  5. ğŸ”® Multi-step prediction (Ã§ok adÄ±mlÄ± tahmin)
  6. ğŸ“ˆ GerÃ§ek zamanlÄ± tahmin uygulamasÄ±

ğŸ’¡ LSTM'in avantajlarÄ± bu Ã¶rnekte gÃ¶rÃ¼ldÃ¼:
  âœ… Uzun vadeli baÄŸÄ±mlÄ±lÄ±klarÄ± Ã¶ÄŸrenebilir
  âœ… Gradient vanishing problemi olmaz
  âœ… Kompleks zaman serilerinde baÅŸarÄ±lÄ±
  âœ… Multi-step prediction yapabilir

ğŸ“ˆ Model performansÄ±:
  â€¢ Test MAE: 8.51$
  â€¢ Test MAPE: 4.48%
  â€¢ Model, ortalama 4.5% hata ile tahmin yapÄ±yor

ğŸ”„ Model iyileÅŸtirme Ã¶nerileri:
  1. Daha fazla feature (teknik gÃ¶stergeler)
  2. Attention mekanizmasÄ± ekleme
  3. Ensemble modeller kullanma
  4. Hiperparametre optimizasyonu

ğŸ“š Sonraki dosya: 06_gru_example.py
GRU (Gated Recurrent Unit) ile LSTM'i karÅŸÄ±laÅŸtÄ±racaÄŸÄ±z!
âœ… LSTM Ã–RNEÄÄ° TAMAMLANDI!
-----------------------------------