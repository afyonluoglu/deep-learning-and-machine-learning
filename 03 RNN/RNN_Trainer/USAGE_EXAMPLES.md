# RNN Trainer - DetaylÄ± KullanÄ±m Ã–rnekleri

Bu dosya, RNN Trainer uygulamasÄ±nÄ±n Ã§eÅŸitli kullanÄ±m senaryolarÄ±nÄ± adÄ±m adÄ±m Ã¶rneklerle aÃ§Ä±klamaktadÄ±r.

## ğŸ“‹ Ä°Ã§indekiler

1. [BaÅŸlangÄ±Ã§ Seviyesi Ã–rnekler](#baÅŸlangÄ±Ã§-seviyesi-Ã¶rnekler)
2. [Orta Seviye Ã–rnekler](#orta-seviye-Ã¶rnekler)
3. [Ä°leri Seviye Ã–rnekler](#ileri-seviye-Ã¶rnekler)
4. [Parametre Optimizasyon Ã–rnekleri](#parametre-optimizasyon-Ã¶rnekleri)
5. [Hata AyÄ±klama SenaryolarÄ±](#hata-ayÄ±klama-senaryolarÄ±)

---

## BaÅŸlangÄ±Ã§ Seviyesi Ã–rnekler

### Ã–rnek 1: Ä°lk RNN Modeliniz - Basit SinÃ¼s DalgasÄ±

**Hedef**: RNN'in basit bir periyodik Ã¶rÃ¼ntÃ¼yÃ¼ nasÄ±l Ã¶ÄŸrendiÄŸini anlamak.

**AdÄ±m AdÄ±m**:

1. **UygulamayÄ± BaÅŸlatÄ±n**
   ```bash
   python rnn_trainer_app.py
   ```

2. **Model Parametrelerini AyarlayÄ±n** (Sol panel - Model Parameters bÃ¶lÃ¼mÃ¼)
   - Hidden Units: `20` (slider'Ä± 20'ye getirin)
   - Learning Rate: `0.01` (slider'Ä± 0.01'e getirin)
   - Sequence Length: `20` (slider'Ä± 20'ye getirin)
   - Activation Function: `tanh` (dropdown'dan seÃ§in)

3. **"Initialize Model" Butonuna TÄ±klayÄ±n**
   - Popup mesaj: "Model initialized successfully!" gÃ¶receksiniz
   - Status bar: Model bilgilerini gÃ¶sterecek

4. **Veri Ãœretin** (Data Generation bÃ¶lÃ¼mÃ¼)
   - Wave Type: `Sine Wave` seÃ§in
   - Samples: `500`
   - Frequency: `1.0`
   - Noise Level: `0.05`

5. **"Generate Data" Butonuna TÄ±klayÄ±n**
   - SaÄŸ Ã¼st grafikte mavi sinÃ¼s dalgasÄ± gÃ¶rÃ¼necek
   - Status bar: "Generated Sine Wave: 500 samples..." gÃ¶sterecek

6. **EÄŸitim BaÅŸlatÄ±n** (Training bÃ¶lÃ¼mÃ¼)
   - Epochs: `100`
   - **"Start Training"** butonuna tÄ±klayÄ±n

7. **EÄŸitimi Ä°zleyin**
   - Alt grafikte loss deÄŸeri dÃ¼ÅŸecek (logaritmik Ã¶lÃ§ekte)
   - Status bar her 5 epoch'ta gÃ¼ncellenecek
   - Beklenen sÃ¼re: ~30 saniye

8. **Test Edin**
   - EÄŸitim bitince **"Test Prediction"** tÄ±klayÄ±n
   - Ãœst grafikte:
     - Mavi Ã§izgi: GerÃ§ek veri
     - KÄ±rmÄ±zÄ± kesikli Ã§izgi: Model tahmini
   - Popup'ta MSE deÄŸerini gÃ¶rÃ¼n (beklenen: < 0.02)

**Beklenen SonuÃ§**:
- Loss: ~0.001 seviyesine dÃ¼ÅŸmeli
- Tahminler gerÃ§ek veriyi Ã§ok yakÄ±n takip etmeli
- MSE < 0.02 olmalÄ±

**Ã–ÄŸrenilenler**:
- âœ… RNN periyodik Ã¶rÃ¼ntÃ¼leri Ã¶ÄŸrenebilir
- âœ… Loss deÄŸeri dÃ¼zenli azalmalÄ±
- âœ… Daha fazla epoch daha iyi sonuÃ§ verir

---

### Ã–rnek 2: FarklÄ± Dalga Tiplerini KeÅŸfetme

**Hedef**: FarklÄ± dalga tiplerinin RNN Ã¶ÄŸrenimi Ã¼zerindeki etkisini gÃ¶rmek.

**Test 1: Kare Dalga**
```
Model: AynÄ± (Hidden=20, LR=0.01, SeqLen=20)
Data:
  - Wave Type: Square Wave
  - Samples: 500
  - Frequency: 0.5  (daha yavaÅŸ)
  - Noise: 0.02     (daha az gÃ¼rÃ¼ltÃ¼, keskin geÃ§iÅŸler iÃ§in)
Training: 150 epochs
```

**GÃ¶zlem**:
- Keskin geÃ§iÅŸlerde modelin zorlandÄ±ÄŸÄ±nÄ± gÃ¶receksiniz
- Loss daha yavaÅŸ azalÄ±r
- Tahminler yuvarlatÄ±lmÄ±ÅŸ olacak (RNN'in doÄŸasÄ±)

**Test 2: ÃœÃ§gen Dalga**
```
Model: AynÄ±
Data:
  - Wave Type: Triangular Wave
  - Samples: 500
  - Frequency: 0.8
  - Noise: 0.05
Training: 100 epochs
```

**GÃ¶zlem**:
- DoÄŸrusal rampalar iyi Ã¶ÄŸrenilir
- Tepe noktalarÄ±nda kÃ¼Ã§Ã¼k yuvarlatma
- SinÃ¼sten daha kolay Ã¶ÄŸrenilir

**Test 3: KarÄ±ÅŸÄ±k Dalgalar**
```
Model: Hidden=40 (daha fazla kapasite gerekli)
Data:
  - Wave Type: Mixed Waves
  - Samples: 1000
  - Frequency: 1.5
  - Noise: 0.1
Training: 200 epochs
```

**GÃ¶zlem**:
- Daha karmaÅŸÄ±k, loss daha yavaÅŸ azalÄ±r
- Birden fazla frekansÄ± ayrÄ±ÅŸtÄ±rmaya Ã§alÄ±ÅŸÄ±r
- MSE biraz daha yÃ¼ksek (~0.05-0.1)

**KarÅŸÄ±laÅŸtÄ±rma Tablosu**:
| Dalga Tipi | Epochs | Final Loss | MSE | Zorluk |
|------------|--------|------------|-----|--------|
| Sine       | 100    | ~0.001     | <0.02 | Kolay |
| Square     | 150    | ~0.005     | <0.05 | Orta |
| Triangle   | 100    | ~0.002     | <0.03 | Kolay |
| Mixed      | 200    | ~0.008     | <0.10 | Zor |

---

### Ã–rnek 3: GÃ¼rÃ¼ltÃ¼ Etkisini Anlama

**Hedef**: GÃ¼rÃ¼ltÃ¼nÃ¼n model performansÄ±na etkisini gÃ¶rmek.

**Deney Serisi**: AynÄ± model, aynÄ± veri, sadece gÃ¼rÃ¼ltÃ¼ deÄŸiÅŸiyor

**Model Parametreleri** (sabit):
```
Hidden Units: 30
Learning Rate: 0.01
Sequence Length: 20
Activation: tanh
```

**Veri** (sabit):
```
Wave Type: Sine Wave
Samples: 500
Frequency: 1.0
```

**Deney 1: GÃ¼rÃ¼ltÃ¼sÃ¼z** (Noise = 0.0)
```
Training: 100 epochs
Beklenen MSE: < 0.005
GÃ¶zlem: MÃ¼kemmel fit, model tamamen ezberledi
```

**Deney 2: Hafif GÃ¼rÃ¼ltÃ¼** (Noise = 0.05)
```
Training: 100 epochs
Beklenen MSE: ~0.02
GÃ¶zlem: Ã‡ok iyi, ana Ã¶rÃ¼ntÃ¼ korundu
```

**Deney 3: Orta GÃ¼rÃ¼ltÃ¼** (Noise = 0.15)
```
Training: 150 epochs
Beklenen MSE: ~0.08
GÃ¶zlem: Ä°yi, model gÃ¼rÃ¼ltÃ¼yÃ¼ filtreledi
```

**Deney 4: YÃ¼ksek GÃ¼rÃ¼ltÃ¼** (Noise = 0.3)
```
Training: 200 epochs
Beklenen MSE: ~0.15
GÃ¶zlem: ZorlanÄ±yor ama ana trendi yakalÄ±yor
```

**Ã–nemli Notlar**:
- ğŸ” GÃ¼rÃ¼ltÃ¼ generalizasyonu artÄ±rÄ±r
- âš ï¸ Ã‡ok fazla gÃ¼rÃ¼ltÃ¼ Ã¶ÄŸrenmeyi zorlaÅŸtÄ±rÄ±r
- ğŸ’¡ Optimal: 0.05-0.1 arasÄ±

---

## Orta Seviye Ã–rnekler

### Ã–rnek 4: Learning Rate Optimizasyonu

**Hedef**: Optimal learning rate'i bulmak.

**Sabit Parametreler**:
```
Hidden Units: 25
Sequence Length: 20
Activation: tanh
Data: Sine Wave (500 samples, freq=1.0, noise=0.05)
Epochs: 100
```

**Test Serisi**:

**Test A: Ã‡ok DÃ¼ÅŸÃ¼k LR** (0.001)
```
Learning Rate: 0.001
SonuÃ§:
  - Loss Ã§ok yavaÅŸ azalÄ±r
  - 100 epoch yetmez
  - Final Loss: ~0.05
  - Durum: Underfitting
Ã‡Ã¶zÃ¼m: LR artÄ±r
```

**Test B: DÃ¼ÅŸÃ¼k LR** (0.005)
```
Learning Rate: 0.005
SonuÃ§:
  - Loss dÃ¼zenli azalÄ±r
  - Stabil eÄŸitim
  - Final Loss: ~0.01
  - Durum: Ä°yi ama yavaÅŸ
```

**Test C: Optimal LR** (0.01)
```
Learning Rate: 0.01
SonuÃ§:
  - Loss hÄ±zla azalÄ±r
  - Stabil ve hÄ±zlÄ±
  - Final Loss: ~0.002
  - Durum: OPTIMAL âœ“
```

**Test D: YÃ¼ksek LR** (0.05)
```
Learning Rate: 0.05
SonuÃ§:
  - Loss salÄ±nÄ±m yapar
  - KararsÄ±z eÄŸitim
  - Final Loss: ~0.02 (salÄ±nÄ±mlÄ±)
  - Durum: Ã‡ok yÃ¼ksek
Ã‡Ã¶zÃ¼m: LR azalt
```

**Test E: Ã‡ok YÃ¼ksek LR** (0.1)
```
Learning Rate: 0.1
SonuÃ§:
  - Loss diverge olabilir (artar)
  - Ã‡ok kararsÄ±z
  - Final Loss: ArtÄ±yor!
  - Durum: Divergence
Ã‡Ã¶zÃ¼m: Ã‡ok azalt
```

**Grafik Analizi**:
```
LR = 0.001: ________   (dÃ¼z, yavaÅŸ)
LR = 0.005: \____      (dÃ¼zenli dÃ¼ÅŸÃ¼ÅŸ)
LR = 0.01:  \___       (hÄ±zlÄ± dÃ¼ÅŸÃ¼ÅŸ) â† OPTIMAL
LR = 0.05:  \/\/\/\    (salÄ±nÄ±mlÄ±)
LR = 0.1:   /\/\       (diverge)
```

---

### Ã–rnek 5: Hidden Units Kapasitesi

**Hedef**: Model kapasitesinin etkisini anlamak.

**Senaryo**: KarmaÅŸÄ±k Mixed Waves Ã¶ÄŸrenimi

**Veri**:
```
Wave Type: Mixed Waves
Samples: 1000
Frequency: 2.0
Noise: 0.1
```

**Sabit Parametreler**:
```
Learning Rate: 0.01
Sequence Length: 25
Activation: tanh
Epochs: 150
```

**Test A: KÃ¼Ã§Ã¼k Model** (Hidden = 10)
```
Hidden Units: 10
Total Parameters: ~131

SonuÃ§:
  - Yetersiz kapasite
  - Ana frekansÄ± yakalÄ±yor
  - DetaylarÄ± kaÃ§Ä±rÄ±yor
  - MSE: ~0.15
  - Durum: UNDERFITTING

GÃ¶zlem: Model Ã§ok basit, karmaÅŸÄ±k Ã¶rÃ¼ntÃ¼ iÃ§in yetersiz
```

**Test B: Orta Model** (Hidden = 30)
```
Hidden Units: 30
Total Parameters: ~991

SonuÃ§:
  - Ä°yi denge
  - Ana Ã¶rÃ¼ntÃ¼ ve bazÄ± detaylar
  - MSE: ~0.08
  - Durum: Ä°YÄ°

GÃ¶zlem: Dengeli kapasite
```

**Test C: BÃ¼yÃ¼k Model** (Hidden = 60)
```
Hidden Units: 60
Total Parameters: ~3,721

SonuÃ§:
  - MÃ¼kemmel fit
  - TÃ¼m detaylarÄ± yakalÄ±yor
  - MSE: ~0.04
  - Durum: Ã‡OK Ä°YÄ°
  - UyarÄ±: EÄŸitim 2x daha yavaÅŸ

GÃ¶zlem: YÃ¼ksek kapasite, en iyi sonuÃ§
```

**Test D: Ã‡ok BÃ¼yÃ¼k Model** (Hidden = 100)
```
Hidden Units: 100
Total Parameters: ~10,201

SonuÃ§:
  - MÃ¼kemmel fit (60 ile aynÄ±)
  - MSE: ~0.04 (iyileÅŸme yok!)
  - Durum: OVERPARAMETERIZED
  - UyarÄ±: EÄŸitim 4x daha yavaÅŸ

GÃ¶zlem: Gereksiz kapasite, verimlilik kaybÄ±
```

**Optimal SeÃ§im**: Hidden = 60 (en iyi MSE/hÄ±z dengesi)

---

### Ã–rnek 6: Sequence Length Optimizasyonu

**Hedef**: DoÄŸru sequence length'i bulmak.

**Problem**: Damped Oscillation (sÃ¶nÃ¼mlÃ¼ salÄ±nÄ±m) Ã¶ÄŸrenimi

**Veri**:
```
Wave Type: Damped Oscillation
Samples: 800
Frequency: 1.0
Damping: 0.1
Noise: 0.05
```

**Model**:
```
Hidden Units: 30
Learning Rate: 0.01
Activation: tanh
Epochs: 150
```

**Analiz**: Damped oscillation'Ä±n periyodu ~20 adÄ±m

**Test A: Ã‡ok KÄ±sa** (SeqLen = 5)
```
Sequence Length: 5

SonuÃ§:
  - Yerel Ã¶rÃ¼ntÃ¼leri yakalar
  - Uzun vadeli trendi kaÃ§Ä±rÄ±r
  - MSE: ~0.12
  
GÃ¶zlem: Pencere Ã§ok dar, genel dinamiÄŸi gÃ¶rmÃ¼yor
```

**Test B: KÄ±sa** (SeqLen = 15)
```
Sequence Length: 15

SonuÃ§:
  - KÄ±sa vadeli tahminler iyi
  - SÃ¶nÃ¼mleme trendini kÄ±smen yakalar
  - MSE: ~0.08
  
GÃ¶zlem: Biraz daha iyi ama hala yetersiz
```

**Test C: Optimal** (SeqLen = 25)
```
Sequence Length: 25

SonuÃ§:
  - Tam bir periyodu gÃ¶rebiliyor
  - Hem salÄ±nÄ±mÄ± hem sÃ¶nÃ¼mlemeyi Ã¶ÄŸreniyor
  - MSE: ~0.04
  - Durum: OPTIMAL âœ“
  
GÃ¶zlem: Periyottan biraz uzun = ideal
```

**Test D: Uzun** (SeqLen = 40)
```
Sequence Length: 40

SonuÃ§:
  - Ã‡ok iyi sonuÃ§lar
  - MSE: ~0.04 (25 ile aynÄ±)
  - UyarÄ±: EÄŸitim daha yavaÅŸ
  
GÃ¶zlem: Ek kazanÃ§ yok, gereksiz uzun
```

**Kural**: Sequence Length â‰ˆ 1.2 Ã— Periyot

---

## Ä°leri Seviye Ã–rnekler

### Ã–rnek 7: Model Persistency - Kaydetme ve YÃ¼kleme

**Hedef**: EÄŸitilmiÅŸ modeli kaydetme ve yeniden kullanma.

**Senaryo 1: Model EÄŸitimi ve Kaydetme**

1. **Ä°lk EÄŸitim**:
   ```
   Model:
     - Hidden Units: 40
     - Learning Rate: 0.01
     - Sequence Length: 25
     - Activation: tanh
   
   Data:
     - Wave Type: ARMA
     - Samples: 1000
     - Noise: 0.1
   
   Training:
     - Epochs: 300
     - Final Loss: ~0.005
     - MSE: ~0.06
   ```

2. **Modeli Kaydedin**:
   - "Save Model" butonuna tÄ±klayÄ±n
   - Dosya adÄ±: `arma_model_v1.pkl`
   - Konum: `RNN_Trainer/models/` (klasÃ¶r oluÅŸturun)
   - Otomatik oluÅŸur: `arma_model_v1_config.json`

3. **UygulamayÄ± KapatÄ±n ve Yeniden AÃ§Ä±n**

**Senaryo 2: Model YÃ¼kleme ve Test**

1. **Modeli YÃ¼kleyin**:
   - "Load Model" butonuna tÄ±klayÄ±n
   - `arma_model_v1.pkl` seÃ§in
   - Parametreler otomatik yÃ¼klenir

2. **Yeni Veri Ãœretin** (aynÄ± tip):
   ```
   Wave Type: ARMA (aynÄ± parametreler)
   Samples: 500
   ```

3. **Test Edin**:
   - "Test Prediction" tÄ±klayÄ±n
   - Model direkt Ã§alÄ±ÅŸÄ±r (eÄŸitimsiz!)
   - MSE kontrol edin

**Senaryo 3: Transfer Learning - Devam EÄŸitimi**

1. **YÃ¼klenen Model ile Devam**:
   - Model zaten yÃ¼klÃ¼
   - FarklÄ± veri Ã¼retin (Ã¶rn: biraz farklÄ± parametreler)
   - Epochs: 50 (fine-tuning)
   - "Start Training" tÄ±klayÄ±n

2. **GeliÅŸmiÅŸ Model Olarak Kaydedin**:
   - "Save Model"
   - Dosya adÄ±: `arma_model_v2.pkl`

**KullanÄ±m SenaryolarÄ±**:
- âœ… Uzun eÄŸitimleri bÃ¶lmek
- âœ… FarklÄ± veri setlerinde test
- âœ… Model versiyonlama
- âœ… En iyi modeli koruma
- âœ… Ekip iÃ§inde paylaÅŸÄ±m

---

### Ã–rnek 8: Ã‡oklu Model KarÅŸÄ±laÅŸtÄ±rmasÄ±

**Hedef**: Birden fazla konfigÃ¼rasyon denemek ve en iyisini seÃ§mek.

**Problem**: Polynomial trend prediction

**Veri** (sabit):
```
Wave Type: Polynomial
Samples: 800
Coefficients: [0, 0.5, 0.1]
Noise: 0.08
```

**Model VaryasyonlarÄ±**:

**Model A: "Fast"**
```
Hidden Units: 15
Learning Rate: 0.02
Sequence Length: 15
Epochs: 100

EÄŸit â†’ Test â†’ Kaydet: "poly_model_fast.pkl"

SonuÃ§:
  - EÄŸitim sÃ¼resi: ~20 saniye
  - MSE: 0.12
  - Notlar: HÄ±zlÄ± ama orta doÄŸruluk
```

**Model B: "Balanced"**
```
Hidden Units: 30
Learning Rate: 0.01
Sequence Length: 25
Epochs: 150

EÄŸit â†’ Test â†’ Kaydet: "poly_model_balanced.pkl"

SonuÃ§:
  - EÄŸitim sÃ¼resi: ~45 saniye
  - MSE: 0.06
  - Notlar: Ä°yi denge
```

**Model C: "Accurate"**
```
Hidden Units: 50
Learning Rate: 0.008
Sequence Length: 35
Epochs: 250

EÄŸit â†’ Test â†’ Kaydet: "poly_model_accurate.pkl"

SonuÃ§:
  - EÄŸitim sÃ¼resi: ~90 saniye
  - MSE: 0.03
  - Notlar: En iyi doÄŸruluk
```

**Model D: "Experimental"** (relu activation)
```
Hidden Units: 40
Learning Rate: 0.01
Sequence Length: 25
Activation: relu  (farklÄ±!)
Epochs: 150

EÄŸit â†’ Test â†’ Kaydet: "poly_model_relu.pkl"

SonuÃ§:
  - EÄŸitim sÃ¼resi: ~40 saniye
  - MSE: 0.08
  - Notlar: ReLU bu problem iÃ§in tanh'dan kÃ¶tÃ¼
```

**KarÅŸÄ±laÅŸtÄ±rma Tablosu**:
| Model | Hidden | LR | SeqLen | Act | Epochs | Time | MSE | Score |
|-------|--------|-------|--------|-----|--------|------|-----|-------|
| Fast | 15 | 0.020 | 15 | tanh | 100 | 20s | 0.12 | â­â­ |
| Balanced | 30 | 0.010 | 25 | tanh | 150 | 45s | 0.06 | â­â­â­â­ |
| Accurate | 50 | 0.008 | 35 | tanh | 250 | 90s | 0.03 | â­â­â­â­â­ |
| Experimental | 40 | 0.010 | 25 | relu | 150 | 40s | 0.08 | â­â­â­ |

**SonuÃ§**: "Balanced" en iyi MSE/sÃ¼re dengesi!

---

### Ã–rnek 9: Aktivasyon Fonksiyonu Analizi

**Hedef**: tanh vs relu karÅŸÄ±laÅŸtÄ±rmasÄ±

**Test Veri Setleri**:

**Dataset 1: Sine Wave** ([-1, 1] aralÄ±ÄŸÄ±nda)
```
Samples: 500, Frequency: 1.0, Noise: 0.05

Model Tanh:
  Hidden: 25, LR: 0.01, SeqLen: 20, Epochs: 100
  MSE: 0.018
  GÃ¶zlem: MÃ¼kemmel, tanh [-1,1] iÃ§in ideal

Model ReLU:
  Hidden: 25, LR: 0.01, SeqLen: 20, Epochs: 100
  MSE: 0.035
  GÃ¶zlem: Ä°yi ama tanh kadar deÄŸil
  
Kazanan: TANH âœ“
```

**Dataset 2: Exponential** (pozitif, bÃ¼yÃ¼yen)
```
Samples: 600, Growth: 0.02, Noise: 0.05

Model Tanh:
  Hidden: 30, LR: 0.01, SeqLen: 25, Epochs: 150
  MSE: 0.08
  GÃ¶zlem: ZorlanÄ±yor, saturation problemi

Model ReLU:
  Hidden: 30, LR: 0.01, SeqLen: 25, Epochs: 150
  MSE: 0.05
  GÃ¶zlem: Daha iyi, pozitif deÄŸerler iÃ§in uygun
  
Kazanan: RELU âœ“
```

**Dataset 3: Square Wave** (keskin geÃ§iÅŸler)
```
Samples: 500, Frequency: 0.5, Noise: 0.02

Model Tanh:
  Hidden: 35, LR: 0.01, SeqLen: 20, Epochs: 150
  MSE: 0.045
  GÃ¶zlem: Kenarlar yuvarlatÄ±lmÄ±ÅŸ

Model ReLU:
  Hidden: 35, LR: 0.01, SeqLen: 20, Epochs: 150
  MSE: 0.052
  GÃ¶zlem: Daha yuvarlatÄ±lmÄ±ÅŸ, dying ReLU problemi
  
Kazanan: TANH âœ“
```

**Genel Kural**:
- **Tanh**: Bounded data ([-1,1]), smooth patterns â†’ Ã–nerilen
- **ReLU**: Unbounded data, sparse activations â†’ BazÄ± durumlarda

---

## Parametre Optimizasyon Ã–rnekleri

### Ã–rnek 10: Grid Search ile En Ä°yi Parametreleri Bulma

**Hedef**: Sistematik parametre aramasÄ±

**Problem**: Mixed Waves optimal konfigÃ¼rasyonu

**Veri** (sabit):
```
Wave Type: Mixed Waves
Samples: 800
Frequency: 1.5
Noise: 0.1
```

**Grid Search Parametreleri**:
```
Hidden Units: [20, 30, 40]
Learning Rate: [0.005, 0.01, 0.02]
Sequence Length: [20, 30]
```

**Toplam Kombinasyon**: 3 Ã— 3 Ã— 2 = 18 test

**ProsedÃ¼r**:

1. **Her kombinasyon iÃ§in**:
   - Modeli initialize et
   - Veriyi Ã¼ret (aynÄ± seed iÃ§in aynÄ± olacak)
   - 100 epoch eÄŸit
   - Test et
   - MSE kaydet
   - Modeli kaydet (Ã¶rn: `grid_h20_lr005_s20.pkl`)

2. **SonuÃ§larÄ± Kaydet**:

| # | Hidden | LR | SeqLen | MSE | Time |
|---|--------|-------|--------|------|------|
| 1 | 20 | 0.005 | 20 | 0.095 | 25s |
| 2 | 20 | 0.005 | 30 | 0.088 | 28s |
| 3 | 20 | 0.010 | 20 | 0.082 | 24s |
| 4 | 20 | 0.010 | 30 | 0.079 | 27s |
| 5 | 20 | 0.020 | 20 | 0.091 | 23s |
| 6 | 20 | 0.020 | 30 | 0.086 | 26s |
| 7 | 30 | 0.005 | 20 | 0.071 | 35s |
| 8 | 30 | 0.005 | 30 | 0.065 | 38s |
| 9 | 30 | 0.010 | 20 | **0.058** | 34s | â† BEST!
| 10 | 30 | 0.010 | 30 | 0.062 | 37s |
| 11 | 30 | 0.020 | 20 | 0.074 | 33s |
| 12 | 30 | 0.020 | 30 | 0.068 | 36s |
| 13 | 40 | 0.005 | 20 | 0.069 | 48s |
| 14 | 40 | 0.005 | 30 | 0.063 | 51s |
| 15 | 40 | 0.010 | 20 | 0.061 | 47s |
| 16 | 40 | 0.010 | 30 | 0.059 | 50s |
| 17 | 40 | 0.020 | 20 | 0.076 | 46s |
| 18 | 40 | 0.020 | 30 | 0.071 | 49s |

**En Ä°yi KonfigÃ¼rasyon**:
```
âœ“ Hidden Units: 30
âœ“ Learning Rate: 0.01
âœ“ Sequence Length: 20
âœ“ MSE: 0.058
âœ“ Time: 34s (orta)
```

**Ä°kinci En Ä°yi** (daha yavaÅŸ ama biraz daha iyi):
```
â€¢ Hidden Units: 40
â€¢ Learning Rate: 0.01
â€¢ Sequence Length: 30
â€¢ MSE: 0.059
â€¢ Time: 50s
```

**Ä°Ã§gÃ¶rÃ¼ler**:
- Hidden 30-40 arasÄ± optimal
- LR 0.01 en dengeli
- SeqLen 20 yeterli (30 Ã§ok az iyileÅŸtirme)
- LR 0.02 Ã§ok yÃ¼ksek (her hidden size'da kÃ¶tÃ¼)

---

## Hata AyÄ±klama SenaryolarÄ±

### Senaryo 1: Loss ArtÄ±yor (Divergence)

**Problem Durumu**:
```
Model: Hidden=25, LR=0.1, SeqLen=20
Data: Sine Wave
Epochs: 50

GÃ¶zlem:
  - Loss baÅŸlangÄ±Ã§ta 0.5
  - Epoch 10'da 1.2
  - Epoch 20'de 3.5
  - Epoch 30'da 8.9
  - Loss patladÄ±!
```

**TeÅŸhis**:
- Learning rate Ã§ok yÃ¼ksek
- AÄŸÄ±rlÄ±klar optimize noktasÄ±nÄ± aÅŸÄ±yor

**Ã‡Ã¶zÃ¼m AdÄ±mlarÄ±**:

1. **Stop Training** butonuna bas
2. Learning Rate'i 0.01'e dÃ¼ÅŸÃ¼r
3. "Initialize Model" ile modeli sÄ±fÄ±rla
4. "Start Training" tekrar baÅŸlat

**SonuÃ§**:
```
Epochs: 50
Final Loss: 0.003
Durum: Ã‡Ã¶zÃ¼ldÃ¼ âœ“
```

**Ã–nleyici Tedbirler**:
- LR > 0.05 kullanma
- Gradient clipping aktif (otomatik)
- Ä°lk birkaÃ§ epoch'u izle

---

### Senaryo 2: Loss PlatolaÅŸtÄ±

**Problem Durumu**:
```
Model: Hidden=10, LR=0.01, SeqLen=20
Data: Mixed Waves
Epochs: 200

GÃ¶zlem:
  - Epoch 0-50: Loss 0.5 â†’ 0.2
  - Epoch 50-100: Loss 0.2 â†’ 0.15
  - Epoch 100-200: Loss 0.15 â†’ 0.15 (deÄŸiÅŸmiyor!)
```

**TeÅŸhis**:
- Model kapasitesi yetersiz
- Underfitting

**Ã‡Ã¶zÃ¼m AdÄ±mlarÄ±**:

1. **Stop Training**
2. Hidden Units'i 30'a Ã§Ä±kar
3. "Initialize Model"
4. Veriyi tekrar Ã¼ret (aynÄ± olacak)
5. "Start Training"

**SonuÃ§**:
```
Epochs: 200
Final Loss: 0.05
Durum: Ã‡Ã¶zÃ¼ldÃ¼ âœ“ (daha fazla kapasite yardÄ±m etti)
```

**Alternatif Ã‡Ã¶zÃ¼mler**:
- Learning Rate artÄ±r (0.01 â†’ 0.02)
- Sequence Length artÄ±r
- Her ikisi

---

### Senaryo 3: Overfitting Tespit

**Problem Durumu**:
```
Model: Hidden=80, LR=0.01, SeqLen=20
Data: Sine Wave (clean, noise=0.0)
Epochs: 300

Training SonrasÄ±:
  - Training MSE: 0.001 (mÃ¼kemmel!)
  
Yeni Test Verisi Ãœret (aynÄ± tip, farklÄ± gÃ¼rÃ¼ltÃ¼):
  - Test MSE: 0.15 (Ã§ok kÃ¶tÃ¼!)
```

**TeÅŸhis**:
- Model eÄŸitim verisini ezberled i
- Generalize edemiyor

**Ã‡Ã¶zÃ¼m AdÄ±mlarÄ±**:

**YÃ¶ntem 1: Regularization (GÃ¼rÃ¼ltÃ¼)**
```
1. Noise Level'i 0.1'e Ã§Ä±kar
2. Modeli yeniden eÄŸit
3. Test et

SonuÃ§:
  - Training MSE: 0.025
  - Test MSE: 0.03
  - Durum: Ä°yi generalization âœ“
```

**YÃ¶ntem 2: Model Kapasitesi Azalt**
```
1. Hidden Units: 80 â†’ 30
2. Modeli yeniden eÄŸit
3. Test et

SonuÃ§:
  - Training MSE: 0.015
  - Test MSE: 0.02
  - Durum: Daha dengeli âœ“
```

**YÃ¶ntem 3: Erken Durdurma**
```
1. 300 epochs yerine 100 epochs
2. Loss plato olduÄŸunda dur
```

---

### Senaryo 4: YavaÅŸ EÄŸitim

**Problem Durumu**:
```
Model: Hidden=100, LR=0.005, SeqLen=50
Data: 2000 samples
Epochs: 500

GÃ¶zlem:
  - Her epoch ~5 saniye sÃ¼rÃ¼yor
  - Toplam: 500 Ã— 5s = ~40 dakika!
  - Ã‡ok yavaÅŸ!
```

**TeÅŸhis**:
- Ã‡ok bÃ¼yÃ¼k model
- Ã‡ok fazla veri
- Uzun sequence

**HÄ±zlandÄ±rma AdÄ±mlarÄ±**:

**Optimizasyon 1: Parametreleri Azalt**
```
Hidden: 100 â†’ 50
SeqLen: 50 â†’ 30
Samples: 2000 â†’ 1000

SonuÃ§: Her epoch ~1.5 saniye (3x hÄ±zlanma)
MSE: Sadece %10 kÃ¶tÃ¼leÅŸti
```

**Optimizasyon 2: Erken Durdurma**
```
Epochs: 500 â†’ 150
(Loss 100. epoch'tan sonra Ã§ok az iyileÅŸiyordu)

SonuÃ§: Toplam sÃ¼re 7.5 dakika
MSE: Hemen hemen aynÄ±
```

**Optimizasyon 3: Learning Rate ArtÄ±r**
```
LR: 0.005 â†’ 0.015
Epochs: 150 â†’ 100

SonuÃ§: Daha az epoch'ta aynÄ± sonuÃ§
Toplam sÃ¼re: 5 dakika
```

**Final KonfigÃ¼rasyon**:
```
Hidden: 50
LR: 0.015
SeqLen: 30
Samples: 1000
Epochs: 100

Toplam sÃ¼re: 5 dakika (40'dan 8x hÄ±zlanma!)
MSE: Orijinal ile %95 aynÄ±
```

---

### Senaryo 5: Tahminler Tamamen YanlÄ±ÅŸ

**Problem Durumu**:
```
Model eÄŸitildi, loss azaldÄ±, ama tahminler saÃ§ma

Training:
  - Final Loss: 0.01 (iyi gÃ¶rÃ¼nÃ¼yor)
  - 100 epochs

Test Prediction:
  - GerÃ§ek veri: SinÃ¼s dalgasÄ± [-1, 1]
  - Tahminler: Sabit Ã§izgi (0.0)
  - Model hiÃ§bir ÅŸey Ã¶ÄŸrenmemiÅŸ gibi!
```

**OlasÄ± Nedenler ve Ã‡Ã¶zÃ¼mler**:

**Neden 1: Veri Normalizasyonu Problemi**
```
Kontrol: Data min/max deÄŸerleri
Ã‡Ã¶zÃ¼m: Veriyi yeniden Ã¼ret (otomatik normalize olur)
```

**Neden 2: Model Initialize EdilmemiÅŸ**
```
Kontrol: "Initialize Model" butonu basÄ±ldÄ± mÄ±?
Ã‡Ã¶zÃ¼m: Model parametrelerini ayarla ve initialize et
```

**Neden 3: YanlÄ±ÅŸ Sequence Length**
```
Kontrol: SeqLen Ã§ok mu kÄ±sa? (Ã¶rn: SeqLen=2)
Ã‡Ã¶zÃ¼m: SeqLen'i en az 10'a Ã§Ä±kar
```

**Neden 4: Vanishing Gradients**
```
Kontrol: Ã‡ok uzun sequence (>50) kullanÄ±ldÄ± mÄ±?
Ã‡Ã¶zÃ¼m: SeqLen'i azalt, LR artÄ±r
```

**Debug ProsedÃ¼rÃ¼**:
```
1. Model Info butonuna bas â†’ Parametreleri kontrol et
2. Basit veri ile test et (Sine, noise=0.0)
3. KÃ¼Ã§Ã¼k model ile test et (Hidden=10, epochs=50)
4. Ã‡alÄ±ÅŸÄ±rsa, parametreleri yavaÅŸÃ§a artÄ±r
```

---

## ğŸ“ SonuÃ§ ve Ä°puÃ§larÄ±

### Genel BaÅŸlangÄ±Ã§ Tavsiyesi:
```
âœ“ Hidden Units: 20-30
âœ“ Learning Rate: 0.01
âœ“ Sequence Length: 20
âœ“ Activation: tanh
âœ“ Epochs: 100
âœ“ Data: Sine Wave, 500 samples, noise=0.05
```

### Ä°lerleme Yolu:
1. Basit â†’ KarmaÅŸÄ±k veri
2. KÃ¼Ã§Ã¼k â†’ BÃ¼yÃ¼k model
3. Az â†’ Ã‡ok epoch
4. Temiz â†’ GÃ¼rÃ¼ltÃ¼lÃ¼ veri

### Deneme SÄ±rasÄ±:
1. Veri tipini deÄŸiÅŸtir
2. GÃ¼rÃ¼ltÃ¼ seviyesini ayarla
3. Learning rate optimize et
4. Hidden units ayarla
5. Sequence length bul
6. Aktivasyon dene

BaÅŸarÄ±lar! ğŸš€
