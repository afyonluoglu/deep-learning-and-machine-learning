"""
Model YÃ¶netim ModÃ¼lÃ¼
Modellerin kaydedilmesi ve yÃ¼klenmesi iÃ§in fonksiyonlar
"""

import torch
import json
import os
from datetime import datetime
from typing import Dict, Tuple, List, Optional
import torch.nn as nn
import numpy as np


class ModelManager:
    """Model kaydetme ve yÃ¼kleme sÄ±nÄ±fÄ±"""
    
    def __init__(self, models_dir: str = "models"):
        CURRENT_DIR = os.path.dirname(os.path.abspath(__file__))
        self.models_dir = os.path.join(CURRENT_DIR, models_dir)        
        print(f"ğŸŸ¢ Model klasÃ¶r yolu: {self.models_dir}")        

        # Models klasÃ¶rÃ¼nÃ¼ oluÅŸtur
        if not os.path.exists(self.models_dir):
            os.makedirs(self.models_dir)
    
    def save_model(self, model: nn.Module, config: Dict, name: str, attention_scores: Dict = None,
                   attention_weights: Optional[np.ndarray] = None, qkv_matrices: Optional[Dict] = None, 
                   history: Optional[Dict] = None):
        """
        Modeli ve konfigÃ¼rasyonu kaydet
        
        Args:
            model: PyTorch modeli
            config: Model konfigÃ¼rasyonu
            name: Model adÄ±
            attention_scores: Attention skorlarÄ± (opsiyonel)
            attention_weights: Attention weight matrisi (opsiyonel)
            qkv_matrices: QKV matrisleri (opsiyonel)
            history: EÄŸitim geÃ§miÅŸi (opsiyonel)
        """
        # Zaman damgasÄ± ekle
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        model_name = f"{name}_{timestamp}"
        
        # KlasÃ¶r oluÅŸtur
        model_path = os.path.join(self.models_dir, model_name)
        os.makedirs(model_path, exist_ok=True)
        
        # Model aÄŸÄ±rlÄ±klarÄ±nÄ± kaydet
        weights_path = os.path.join(model_path, "model_weights.pth")
        torch.save(model.state_dict(), weights_path)
        
        # Tam modeli kaydet (architecture + weights)
        full_model_path = os.path.join(model_path, "full_model.pth")
        torch.save(model, full_model_path)
        
        # KonfigÃ¼rasyonu kaydet
        config_path = os.path.join(model_path, "config.json")
        
        # Token mapping'leri string key'lere Ã§evir
        config_to_save = config.copy()
        if 'idx_to_token' in config_to_save and config_to_save['idx_to_token']:
            config_to_save['idx_to_token'] = {
                str(k): v for k, v in config_to_save['idx_to_token'].items()
            }
        
        with open(config_path, 'w', encoding='utf-8') as f:
            json.dump(config_to_save, f, indent=4, ensure_ascii=False)
        
        # Model bilgilerini kaydet
        info = {
            'name': name,
            'timestamp': timestamp,
            'full_name': model_name,
            'config': config_to_save,
            'save_date': datetime.now().isoformat()
        }
        
        info_path = os.path.join(model_path, "model_info.json")
        with open(info_path, 'w', encoding='utf-8') as f:
            json.dump(info, f, indent=4, ensure_ascii=False)
        
        print(f"âœ… Model kaydedildi: {model_path}")
        
        # Model Ã¶zetini oluÅŸtur ve kaydet
        summary_file = os.path.join(model_path, "model_summary.txt")
        self._generate_and_save_summary(info, summary_file)
        
        # Attention skorlarÄ±nÄ± kaydet (varsa)
        if attention_scores:
            scores_file = os.path.join(model_path, "attention_scores.json")
            self._save_attention_scores(attention_scores, scores_file)
        
        # Attention weights'i kaydet (varsa)
        if attention_weights is not None:
            weights_file = os.path.join(model_path, "attention_weights.npy")
            np.save(weights_file, attention_weights)
            print(f"ğŸ’¾ Attention weights kaydedildi: attention_weights.npy")
        
        # QKV matrislerini kaydet (varsa)
        if qkv_matrices:
            qkv_file = os.path.join(model_path, "qkv_matrices.npz")
            np.savez(qkv_file, 
                    Q=qkv_matrices['Q'], 
                    K=qkv_matrices['K'], 
                    V=qkv_matrices['V'])
            print(f"ğŸ’¾ QKV matrisleri kaydedildi: qkv_matrices.npz")
        
        # EÄŸitim geÃ§miÅŸini kaydet (varsa)
        if history:
            history_file = os.path.join(model_path, "training_history.json")
            # NumPy tiplerini dÃ¶nÃ¼ÅŸtÃ¼r
            def convert_numpy_types(obj):
                if isinstance(obj, np.integer):
                    return int(obj)
                elif isinstance(obj, np.floating):
                    return float(obj)
                elif isinstance(obj, np.ndarray):
                    return obj.tolist()
                elif isinstance(obj, dict):
                    return {key: convert_numpy_types(value) for key, value in obj.items()}
                elif isinstance(obj, list):
                    return [convert_numpy_types(item) for item in obj]
                else:
                    return obj
            
            history_to_save = convert_numpy_types(history)
            with open(history_file, 'w', encoding='utf-8') as f:
                json.dump(history_to_save, f, indent=4, ensure_ascii=False)
            print(f"ğŸ’¾ EÄŸitim geÃ§miÅŸi kaydedildi: training_history.json")
        
        return model_path
    
    def load_model(self, name: str) -> Tuple[nn.Module, Dict, Optional[np.ndarray], 
                                              Optional[Dict], Optional[Dict], Optional[Dict]]:
        """
        Modeli, konfigÃ¼rasyonu ve tÃ¼m ilgili verileri yÃ¼kle
        
        Args:
            name: Model adÄ± (tam klasÃ¶r adÄ±)
            
        Returns:
            (model, config, attention_weights, qkv_matrices, attention_scores, history) tuple'Ä±
        """
        model_path = os.path.join(self.models_dir, name)
        
        if not os.path.exists(model_path):
            raise FileNotFoundError(f"Model bulunamadÄ±: {model_path}")
        
        # KonfigÃ¼rasyonu yÃ¼kle
        config_path = os.path.join(model_path, "config.json")
        with open(config_path, 'r', encoding='utf-8') as f:
            config = json.load(f)
        
        # idx_to_token'Ä± integer key'lere Ã§evir
        if 'idx_to_token' in config and config['idx_to_token']:
            config['idx_to_token'] = {
                int(k): v for k, v in config['idx_to_token'].items()
            }
        
        # Tam modeli yÃ¼kle
        full_model_path = os.path.join(model_path, "full_model.pth")
        
        if not os.path.exists(full_model_path):
            raise FileNotFoundError("Model dosyasÄ± bulunamadÄ±!")
        
        # PyTorch 2.6+ gÃ¼venlik ayarÄ±: weights_only=False gerekli
        # Bu dosya gÃ¼venilir kaynaktan geldiÄŸi iÃ§in (kendi modelimiz) gÃ¼venli
        model = torch.load(full_model_path, weights_only=False)
        print(f"âœ… Model yÃ¼klendi: {model_path}")
        
        # Attention weights'i yÃ¼kle (varsa)
        attention_weights = None
        weights_file = os.path.join(model_path, "attention_weights.npy")
        if os.path.exists(weights_file):
            attention_weights = np.load(weights_file)
            print(f"âœ… Attention weights yÃ¼klendi")
        
        # QKV matrislerini yÃ¼kle (varsa)
        qkv_matrices = None
        qkv_file = os.path.join(model_path, "qkv_matrices.npz")
        if os.path.exists(qkv_file):
            qkv_data = np.load(qkv_file)
            qkv_matrices = {
                'Q': qkv_data['Q'],
                'K': qkv_data['K'],
                'V': qkv_data['V']
            }
            print(f"âœ… QKV matrisleri yÃ¼klendi")
        
        # Attention skorlarÄ±nÄ± yÃ¼kle (varsa)
        attention_scores = None
        scores_file = os.path.join(model_path, "attention_scores.json")
        if os.path.exists(scores_file):
            with open(scores_file, 'r', encoding='utf-8') as f:
                attention_scores = json.load(f)
            print(f"âœ… Attention skorlarÄ± yÃ¼klendi")
        
        # EÄŸitim geÃ§miÅŸini yÃ¼kle (varsa)
        history = None
        history_file = os.path.join(model_path, "training_history.json")
        if os.path.exists(history_file):
            with open(history_file, 'r', encoding='utf-8') as f:
                history = json.load(f)
            print(f"âœ… EÄŸitim geÃ§miÅŸi yÃ¼klendi")
        
        return model, config, attention_weights, qkv_matrices, attention_scores, history
    
    def list_models(self) -> List[str]:
        """KaydedilmiÅŸ modellerin listesini dÃ¶ndÃ¼r"""
        print(f"Modeller listeleniyor: {self.models_dir}")

        if not os.path.exists(self.models_dir):
            return []
        
        models = []
        for item in os.listdir(self.models_dir):
            item_path = os.path.join(self.models_dir, item)
            if os.path.isdir(item_path):
                # Model info dosyasÄ± var mÄ± kontrol et
                info_path = os.path.join(item_path, "model_info.json")
                if os.path.exists(info_path):
                    models.append(item)
        
        return sorted(models, reverse=True)  # En yeni Ã¶nce
    
    def get_model_info(self, name: str) -> Dict:
        """Model bilgilerini al"""
        model_path = os.path.join(self.models_dir, name)
        info_path = os.path.join(model_path, "model_info.json")
        
        if os.path.exists(info_path):
            with open(info_path, 'r', encoding='utf-8') as f:
                return json.load(f)
        
        return {}
    
    def delete_model(self, name: str):
        """Modeli sil"""
        import shutil
        model_path = os.path.join(self.models_dir, name)
        
        if os.path.exists(model_path):
            shutil.rmtree(model_path)
            print(f"Model silindi: {model_path}")
        else:
            print(f"Model bulunamadÄ±: {model_path}")
    
    def _save_attention_scores(self, attention_scores: Dict, output_file: str):
        """
        Attention skorlarÄ±nÄ± dosyaya kaydet
        
        Args:
            attention_scores: Attention skorlarÄ±
            output_file: Ã‡Ä±ktÄ± dosyasÄ±
        """
        # NumPy tiplerini Python native tiplerine Ã§evir
        def convert_numpy_types(obj):
            """NumPy tiplerini JSON-serializable tiplere Ã§evir"""
            import numpy as np
            
            if isinstance(obj, np.integer):
                return int(obj)
            elif isinstance(obj, np.floating):
                return float(obj)
            elif isinstance(obj, np.ndarray):
                return obj.tolist()
            elif isinstance(obj, dict):
                return {key: convert_numpy_types(value) for key, value in obj.items()}
            elif isinstance(obj, list):
                return [convert_numpy_types(item) for item in obj]
            elif isinstance(obj, tuple):
                return tuple(convert_numpy_types(item) for item in obj)
            else:
                return obj
        
        # SkorlarÄ± dÃ¶nÃ¼ÅŸtÃ¼r
        scores_to_save = convert_numpy_types(attention_scores)
        
        # JSON dosyasÄ± olarak kaydet
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(scores_to_save, f, indent=4, ensure_ascii=False)
        
        # Okunabilir metin dosyasÄ± da oluÅŸtur
        txt_file = output_file.replace('.json', '.txt')
        with open(txt_file, 'w', encoding='utf-8') as f:
            f.write("â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n")
            f.write("ATTENTION SKORLARI RAPORU\n")
            f.write("â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\n")
            
            f.write(f"ğŸ“Š Genel Ä°statistikler:\n")
            f.write(f"   â€¢ Ortalama Attention: {attention_scores['avg_attention']:.4f}\n")
            f.write(f"   â€¢ Maksimum Attention: {attention_scores['max_attention']:.4f}\n")
            f.write(f"   â€¢ Minimum Attention: {attention_scores['min_attention']:.4f}\n")
            f.write(f"   â€¢ Token SayÄ±sÄ±: {len(attention_scores['tokens'])}\n\n")
            
            f.write("â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n")
            f.write("TOKEN BAZLI DETAYLAR\n")
            f.write("â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n\n")
            
            for token_data in attention_scores['tokens']:
                f.write(f"\nğŸ”¤ Token: {token_data['token']}\n")
                f.write(f"   Index: {token_data['index']}\n")
                f.write(f"   Self-Attention: {token_data['self_attention']:.4f}\n\n")
                
                f.write(f"   ğŸ“¤ Verilen Attention (Query olarak):\n")
                f.write(f"      Ortalama: {token_data['avg_given']:.4f}\n")
                f.write(f"      Maksimum: {token_data['max_given']:.4f}\n")
                f.write(f"      En Ã§ok attention verdiÄŸi tokenlar:\n")
                for target, score in token_data['top_given']:
                    f.write(f"         â†’ {target}: {score:.4f}\n")
                
                f.write(f"\n   ğŸ“¥ AlÄ±nan Attention (Key olarak):\n")
                f.write(f"      Ortalama: {token_data['avg_received']:.4f}\n")
                f.write(f"      Maksimum: {token_data['max_received']:.4f}\n")
                f.write(f"      En Ã§ok attention aldÄ±ÄŸÄ± tokenlar:\n")
                for source, score in token_data['top_received']:
                    f.write(f"         â† {source}: {score:.4f}\n")
                
                if 'q_norm' in token_data:
                    f.write(f"\n   ğŸ“ QKV Norm DeÄŸerleri:\n")
                    f.write(f"      Q norm: {token_data['q_norm']:.4f}\n")
                    f.write(f"      K norm: {token_data['k_norm']:.4f}\n")
                    f.write(f"      V norm: {token_data['v_norm']:.4f}\n")
                
                f.write("\n" + "â”€"*60 + "\n")
            
            f.write("\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n")
            f.write(f"Rapor OluÅŸturma ZamanÄ±: {datetime.now().strftime('%d.%m.%Y %H:%M:%S')}\n")
            f.write("â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n")
        
        print(f"ğŸ“Š Attention skorlarÄ± kaydedildi:")
        print(f"   â€¢ JSON: {output_file}")
        print(f"   â€¢ TXT:  {txt_file}\n")
    
    def _generate_and_save_summary(self, info: Dict, output_file: str):
        """
        Model Ã¶zetini oluÅŸtur ve kaydet (Internal method)
        
        Args:
            info: Model bilgileri
            output_file: Ã‡Ä±ktÄ± dosyasÄ± yolu
        """
        # Tarih formatÄ±nÄ± daha okunabilir yap
        save_date = info.get('save_date', 'N/A')
        if save_date != 'N/A':
            try:
                from datetime import datetime
                dt = datetime.fromisoformat(save_date)
                save_date = dt.strftime("%d.%m.%Y %H:%M:%S")
            except:
                pass
        
        # Ã–zet oluÅŸtur
        summary = f"""â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
MODEL Ã–ZETÄ° - SELF-ATTENTION Ã–ÄRENME ARACI
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ“‹ GENEL BÄ°LGÄ°LER
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Model AdÄ±          : {info.get('name', 'N/A')}
KayÄ±t Tarihi       : {save_date}
Tam KlasÃ¶r AdÄ±     : {info.get('full_name', 'N/A')}

âš™ï¸ MODEL PARAMETRELERÄ°
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
d_model            : {info['config'].get('d_model', 'N/A')} (Embedding Boyutu)
num_heads          : {info['config'].get('num_heads', 'N/A')} (Attention Head SayÄ±sÄ±)
num_layers         : {info['config'].get('num_layers', 'N/A')} (Katman SayÄ±sÄ±)
dropout            : {info['config'].get('dropout', 'N/A')}
learning_rate      : {info['config'].get('learning_rate', 'N/A')}

ğŸ“š EÄÄ°TÄ°M PARAMETRELERÄ°
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
epochs             : {info['config'].get('epochs', 'N/A')}
batch_size         : {info['config'].get('batch_size', 'N/A')}
vocab_size         : {info['config'].get('vocab_size', len(info['config'].get('vocab', [])))}

ğŸ”¤ VOCABULARY
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Vocabulary Boyutu  : {len(info['config'].get('vocab', []))}
Tokenlar           : {', '.join(info['config'].get('vocab', [])[:20])}{'...' if len(info['config'].get('vocab', [])) > 20 else ''}

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
OluÅŸturulma ZamanÄ±: {datetime.now().strftime("%d.%m.%Y %H:%M:%S")}
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
"""
        
        # Konsola yazdÄ±r
        print("\n" + "="*63)
        print("ğŸ“Š MODEL Ã–ZETÄ° OLUÅTURULDU")
        print("="*63)
        print(summary)
        
        # Dosyaya kaydet
        with open(output_file, 'w', encoding='utf-8') as f:
            f.write(summary)
        print(f"ğŸ’¾ Ã–zet dosyasÄ± kaydedildi: {output_file}\n")
    
    def export_model_summary(self, name: str, output_file: str = None):
        """
        Model Ã¶zetini dÄ±ÅŸa aktar (Public API)
        
        Args:
            name: Model adÄ± (klasÃ¶r adÄ±)
            output_file: Opsiyonel Ã§Ä±ktÄ± dosyasÄ±
        """
        info = self.get_model_info(name)
        
        if not info:
            print("âŒ Model bilgisi bulunamadÄ±!")
            return None
        
        # Ã–zet oluÅŸtur
        if output_file:
            self._generate_and_save_summary(info, output_file)
        else:
            # Sadece konsola yazdÄ±r
            model_path = os.path.join(self.models_dir, name)
            temp_file = os.path.join(model_path, "temp_summary.txt")
            self._generate_and_save_summary(info, temp_file)
            
            # Temp dosyayÄ± oku ve sil
            with open(temp_file, 'r', encoding='utf-8') as f:
                summary = f.read()
            os.remove(temp_file)
            
            return summary
